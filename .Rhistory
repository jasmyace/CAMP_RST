summary(df.and.fit)
summary(df.and.fit[[2]])
for( trap in u.traps ){
cat(paste("==== Catch model for trapPositionID", trap, "========\n" ))
df2 <- catch.df[catch.df$trapPositionID == trap,]
# jason update -- do some zero truncation in the beginning and end.
df2 <- df2[order(df2$batchDate),]    # just in case
df3 <- buff.days(beg.buff=1,end.buff=4,df2)
#   Impute a value for the gaps
#   When df2 comes back from F.catch.model, it has extra lines in it.  One extra line for each 24 hour period in the
#   gaps that were bigger than max.ok.gap. If gap = 3 days, there will be 3 extra lines.
#   sampleStart and sampleEnd for each of the new lines are defined so that no gap appears  now.  Variable
#   'gamEstimated' is true for these periods. Batch date is assigned based on sampleEnd, as usual.
#   On return, there is a value or imputed value for each day from start of season to end of season.
df.and.fit <- suppressWarnings( F.catch.model( df3 ) )  # df.and.fit is list of, $df2 contains data frame, $fit contains model, etc
#jason.df.and.fit <<- df.and.fit
df <- rbind( df, df.and.fit$df2)
catch.fits[[which(trap==u.traps)]] <- df.and.fit$fit
X.miss[[which(trap==u.traps)]] <- df.and.fit$X.for.missings
Gaps[[which(trap==u.traps)]] <- df.and.fit$gaps
bDates.miss[[which(trap==u.traps)]] <- df.and.fit$batchDate.for.missings
true.imp <- rbind(true.imp,df.and.fit$true.imp)
#    print(df.and.fit)
#    cat("in est_catch (hit return):")
#    readline()
}
# true.imp <<- true.imp
cat("in est_catch.r  DF")
print( tapply(df$batchDate, df$trapPositionID, range) )
cat("-------\n")
#   Should probably save df into the Access data base for storage and potential use by others.
#   ---- Now that there are no gaps, sum within traps operating on a batch day, and all checks that occurred on a batch day.
ind <- list( batchDate=format(df$batchDate, "%Y-%m-%d"), trapPositionID=df$trapPositionID  )
est.catch <- tapply( df$n.tot, ind, sum )
p.imputed <- tapply( df$gamEstimated, ind, mean )
est.catch2 <- tapply( df$n.Orig, ind, sum )       # we need to tally up the assigned catch
est.catch3 <- tapply( df$n.Unassd, ind, sum )     # we need to tally up the unassigned catch
tmp.est.catch <- est.catch   # save a copy of est.catch for counting traps later
#   ---- Un-matrix the results and put into a data frame
est.catch <- cbind( expand.grid( batchDate=dimnames(est.catch)[[1]], trapPositionID=dimnames(est.catch)[[2]]),
catch=c(est.catch), imputed.catch=c(p.imputed) )
est.catch2 <- cbind( expand.grid( batchDate=dimnames(est.catch2)[[1]], trapPositionID=dimnames(est.catch2)[[2]]),
assdCatch=c(est.catch2), imputed.catch=c(p.imputed) )    # jason add 4/17/2015.  need to tally up assigned catch
est.catch3 <- cbind( expand.grid( batchDate=dimnames(est.catch3)[[1]], trapPositionID=dimnames(est.catch3)[[2]]),
UnassdCatch=c(est.catch3), imputed.catch=c(p.imputed) )    # jason add 4/17/2015.  need to tally up unassigned catch
# get both total catch and assigned catch and unassigned catch.
est.catch <- merge(est.catch,est.catch2,by=c('batchDate','trapPositionID','imputed.catch'))     # jason add 4/17/2015 - join assumes full join, i.e., dim(of both dfs) same
est.catch <- merge(est.catch,est.catch3,by=c('batchDate','trapPositionID','imputed.catch'))     # jason add 5/20/2015 - join assumes full join, i.e., dim(of both dfs) same
est.catch$batchDate <- as.POSIXct( as.character(est.catch$batchDate), "%Y-%m-%d", tz=time.zone)
est.catch <- est.catch[order(est.catch$trapPositionID,est.catch$batchDate),]
#   ---- Now remove times before and after a trap started and stopped.  The above tapply's using ind inserted NA for days when one trap was not fishing but others where.
#        There are no gaps between the start and stop of a trap in a season, but each trap could operated over a different part of the season.
#        If you want to leave all the days in, comment the following code out.
trapSeasons <- tapply(est.catch$catch, est.catch$trapPositionID, function(x){
seas <- which(!is.na(x))
f <- min(seas)
l <- max(seas)
ans <- rep(FALSE,length(x))
ans[f:l] <- TRUE
ans
})
trapSeasons <- unlist(trapSeasons)
est.catch <- est.catch[ trapSeasons, ]
#   ---- Before we un-matrix-ized est.catch, we saved a copy so we could compute number of traps operating each day because it is easier.
#        But, gaps are filled.  Take back out the gaps when counting.
trapSeasons <- matrix( trapSeasons, nrow=nrow(tmp.est.catch), ncol=ncol(tmp.est.catch) )
for( i in 1:length(bDates.miss) ){
tmp.est.catch[ trapSeasons[,i] & is.na(tmp.est.catch[,i]), i ] <- 0  # Add days when trap was operating but no trap visit.  I.e., trap operated for >24 hours without a check.  Must do this first, before next line.
tmp.est.catch[dimnames(tmp.est.catch)[[1]] %in% format(bDates.miss[[i]]), i] <- NA   #  blank out the gaps.
}
trapsOperating <- apply(tmp.est.catch, 1, function(x){sum(!is.na(x))} )
trapsOperating <- data.frame( batchDate=names(trapsOperating), nTrapsOperating=trapsOperating, stringsAsFactors=F )
trapsOperating$batchDate <- as.POSIXct( as.character(trapsOperating$batchDate), "%Y-%m-%d", tz=time.zone)
#tmp.est.catch <<- tmp.est.catch
#tmp.trapsOperating <<- trapsOperating
#readline()
#   If a trap runs without checks for 48 hours say, it runs over two batch dates.  When this happens,
#   the above statements result in a NA for catch on the day it skipped.  The real (non-imputed) catch
#   for these days is 0.  Replace these NA's with zeros.  (But, perhaps these lines should be tossed...)
#ind <- is.na(est.catch$catch)
#est.catch$catch[ ind ] <- 0
#est.catch$imputed.catch[ ind ] <- 0
#   Assign attributes for plotting
u.ss.rows <- !duplicated(catch.df$trapPositionID)
u.ss <- catch.df$trapPositionID[u.ss.rows]
u.ss.name <- catch.df$TrapPosition[u.ss.rows]
ord <- order( u.ss )
u.ss <- u.ss[ ord ]
u.ss.name <- u.ss.name[ ord ]
#   Make a plot if called for (I don't use parameter 'plot', apparently.
# jason.est.catch <<- est.catch
# jason add:  merge in TrapPosition so that graphical output can show text labels instead of computer code numbers.
# est.catch <- merge(jason.est.catch,unique(catch.dff[,c('trapPositionID','TrapPosition')]),by=c('trapPositionID'),all.x=TRUE)  delete later
est.catch <- merge(est.catch,unique(catch.df[,c('trapPositionID','TrapPosition')]),by=c('trapPositionID'),all.x=TRUE)
attr(est.catch, "site.name") <- catch.df$siteName[1]
attr(est.catch, "subsites") <- data.frame(subSiteID = u.ss, subSiteName=u.ss.name)
attr(est.catch, "run.name") <- run.name#catch.df$FinalRun[1]
attr(est.catch, "life.stage" ) <- catch.df$lifeStage[1]
attr(est.catch, "species.name") <- "Chinook Salmon"
# jason adds 4/20/2015 to itemize out the different types of catches
# collapse imputed to day ... could be two per day if both traps non-functioning
true.imp$shortdate <- strftime(true.imp$batchDate, format="%Y-%m-%d")
true.imp.sum <- aggregate(true.imp$n.tot,by=list(true.imp$shortdate,true.imp$trapPositionID), FUN=sum)
true.imp.sum$batchDate <- as.POSIXct( as.character(true.imp.sum$Group.1), "%Y-%m-%d", tz=time.zone)
true.imp.sum$Group.1 <- NULL
names(true.imp.sum)[names(true.imp.sum) == 'V1'] <- 'n.tot'
names(true.imp.sum)[names(true.imp.sum) == 'Group.2'] <- 'trapPositionID'
preCatch <- merge(est.catch,true.imp.sum,by=c('trapPositionID','batchDate'),all.x=TRUE)
# collpase catch counts in catch.df over day, for both n.tot (totalCatch) and n.Orig (assigned)
catch.df$shortdate  <- strftime(catch.df$batchDate, format="%Y-%m-%d")
catch.df.reduced <- catch.df[catch.df$TrapStatus == 'Fishing',]
catch.df.n.tot.sum <- aggregate(catch.df.reduced$n.tot,by=list(catch.df.reduced$shortdate,catch.df.reduced$trapPositionID), FUN=sum)
catch.df.n.Orig.sum <- aggregate(catch.df.reduced$n.Orig,by=list(catch.df.reduced$shortdate,catch.df.reduced$trapPositionID), FUN=sum)
colnames(catch.df.n.tot.sum) <- c('shortdate','trapPositionID','n.tot')
colnames(catch.df.n.Orig.sum) <- c('shortdate','trapPositionID','n.Orig')
catch.df.both.sum <- merge(catch.df.n.tot.sum,catch.df.n.Orig.sum,by=c('shortdate','trapPositionID'))
catch.df.both.sum$batchDate <- as.POSIXct( as.character(catch.df.both.sum$shortdate), "%Y-%m-%d", tz=time.zone)
catch.df.both.sum$shortdate <- NULL
# full join here to bring in assd data data was observed but not randomly selected...i think
masterCatch <- merge(preCatch,catch.df.both.sum,by=c('trapPositionID','batchDate'),all.x=TRUE,all.y=TRUE)
#masterCatch$unassdCatch <- masterCatch$n.tot.y - masterCatch$n.Orig
masterCatch <- masterCatch[, !(names(masterCatch) %in% c('assdCatch'))]    # we have NA for this var for batchDates with imputation -- its not good enough
names(masterCatch)[names(masterCatch) == 'n.tot.x'] <- 'imputedCatch'
names(masterCatch)[names(masterCatch) == 'catch'] <- 'totalCatch'   # this is trent's old catch col
names(masterCatch)[names(masterCatch) == 'n.Orig'] <- 'assdCatch'
masterCatch <- masterCatch[, !(names(masterCatch) %in% c('trapVisitID','n.tot.y'))]
#   If a trap runs without checks for 48 hours say, it runs over two batch dates.  When this happens,
#   the above statements result in a NA for catch on the day it skipped.  The real (non-imputed) catch
#   for these days is 0.  Replace these NA's with zeros.  (But, perhaps these lines should be tossed...)
getMinDate1 <- masterCatch[!is.na(masterCatch$assdCatch),]
getMinDate2 <- aggregate(getMinDate1[,names(getMinDate1) %in% c('trapPositionID','batchDate')],list(getMinDate1$trapPositionID),FUN=head, 1)
getMinDate2$minDate <- as.POSIXct( as.character(getMinDate2$batchDate), "%Y-%m-%d", tz=time.zone)
masterCatch <- merge(masterCatch,getMinDate2[,c('trapPositionID','minDate')],by='trapPositionID',all.x=TRUE)
masterCatch$indOld <- !is.na(masterCatch$imputedCatch) | !is.na(masterCatch$assdCatch)   # 4/20/2015 reproduce output from before
# masterCatch$assdCatch[ ind ] <- 0
#masterCatch$imputed.catch[ ind ] <- 0
# # adaptation of trent code from before, where he somehow had data only after the first catch day
# ind1 <- (masterCatch$minDate <= masterCatch$batchDate) & is.na(masterCatch$assdCatch)   # 4/20/2015 reproduce output from before
# masterCatch$assdCatch[ ind1 ] <- 0
# ind2 <- (masterCatch$minDate <= masterCatch$batchDate) & is.na(masterCatch$imputed.catch)   # 4/20/2015 reproduce output from before
# masterCatch$imputed.catch[ ind2 ] <- 0
# make sure that totalCatch includes unassdCatch
masterCatch$totalCatch <- ifelse(masterCatch$UnassdCatch > 0 & is.na(masterCatch$totalCatch),masterCatch$UnassdCatch,masterCatch$totalCatch)
# make sure that totalCatch includes imputedCatch -- it was this way before, but breaking things up broke everything
masterCatch$totalCatch <- ifelse(masterCatch$imputedCatch > 0 & is.na(masterCatch$totalCatch),masterCatch$imputedCatch,masterCatch$totalCatch)
# make sure that totalCatch includes assdCatch -- it was this way before, but breaking things up broke everything
masterCatch$totalCatch <- ifelse(masterCatch$assdCatch >= 0 & is.na(masterCatch$totalCatch),masterCatch$assdCatch,masterCatch$totalCatch)
# make sure that imputed.catch is a 1 if no other source of fish for that day.
masterCatch$imputed.catch <- ifelse(masterCatch$imputedCatch >0 & is.na(masterCatch$imputed.catch) & is.na(masterCatch$UnassdCatch) & is.na(masterCatch$assdCatch),1.0,masterCatch$imputed.catch)
attr(masterCatch, "site.name") <- catch.df$siteName[1]
attr(masterCatch, "subsites") <- data.frame(subSiteID = u.ss, subSiteName=u.ss.name)
attr(masterCatch, "run.name") <- run.name#catch.df$FinalRun[1]
attr(masterCatch, "life.stage" ) <- catch.df$lifeStage[1]
attr(masterCatch, "species.name") <- "Chinook Salmon"
#write.csv(masterCatch,'C:/Users/jmitchell/Desktop/masterCatch.csv')
if( !is.na(plot.file) ) {
out.fn <- F.plot.catch.model( masterCatch, file=plot.file )    # change f'n input from est.catch to masterCatch
} else {
out.fn <- NULL
}
cat("Catch estimation complete...\n")
ans <- list(catch=est.catch, fits=catch.fits, X.miss=X.miss, gaps=Gaps, bDates.miss=bDates.miss, trapsOperating=trapsOperating, true.imp=true.imp)
attr(ans, "out.fn.list") <- out.fn
river
river <- ''
river
db.file <- db.file1
dbi.file
db.file
river        <- ''
site         <- 21000
siteText     <- 'testing'
run          <- 3
runText      <- 'Fall'
min.date     <- "2013-11-01"
max.date     <- "2014-06-01"
taxon        <- 161980
#   ---- Check that times are less than 1 year apart
strt.dt <- as.POSIXct( min.date, format="%Y-%m-%d" )
end.dt <- as.POSIXct( max.date, format="%Y-%m-%d" )
run.season <- data.frame( start=strt.dt, end=end.dt )
dt.len <- difftime(end.dt, strt.dt, units="days")
if( dt.len > 366 )  stop("Cannot specify more than 365 days in F.passage. Check min.date and max.date.")
#   ---- Upon input, run is the runID (i.e., 3,4,etc.).  We changed the SQL to Connie's code,
#        and the catch data comes in as run.name (not code).  It is easiest to translate run
#        to the name here.  A bit inefficient, but not much.
ch <- odbcConnectAccess(db.file)
luRun <- sqlFetch(ch, "luRun")
run.name <<- luRun$run[ luRun$runID == run ]
close(ch)
#   ---- Start a progress bar
progbar <<- winProgressBar( "Production estimate", label="Reading catch data and assigning plus-counts" )
#   ---- Fetch the catch and visit data
tmp.df   <- F.get.catch.data( site, taxon, min.date, max.date  )
catch.df <- tmp.df$catch   # All positive catches, all FinalRun and lifeStages, inflated for plus counts.  Zero catches (visits without catch) are NOT here.
visit.df <- tmp.df$visit   # the unique trap visits.  This will be used in a merge to get 0's later
if( nrow(catch.df) == 0 ){
stop( paste( "No catch records between", min.date, "and", max.date, ". Check dates and taxon."))
}
cat("\n\n")
cat(paste(rep("+",150), collapse="")); cat("\n")
cat("\n\n")
#   ---- Fetch efficiency data
setWinProgressBar( progbar, getWinProgressBar(progbar)*.7 + .3 , label="Reading efficiency data" )
release.df <- F.get.release.data( site, taxon, min.date, max.date  )
if( nrow(release.df) == 0 ){
stop( paste( "No efficiency trials between", min.date, "and", max.date, ". Check dates."))
}
cat("\n\n")
cat(paste(rep("+",150), collapse="")); cat("\n")
cat("\n\n")
#   =================================================================
#   by here, we have all the catch, visit, and release data for all runs and lifestages
#          of the species between min and max dates.
#   =================================================================
#   ---- Summarize catch data by batchDate. Upon return, catch.df has one line per trapPosition-batchDate combo during time trap was operating. missing times pre and post season
catch.df1 <- F.summarize.fish.visit( catch.df, 'inflated' )   # jason - 4/14/2015 - we summarize over lifeStage, w/o regard to unassigned.  this is what has always been done.
catch.df2 <- F.summarize.fish.visit( catch.df, 'assigned')    # jason - 4/14/2015 - we summarize over unassigned.  this is new, and necessary to break out by MEASURED, instead of CAUGHT.
#                   - the only reason we do this again is to get a different n.tot.
# bring in counts and stats of measured fish
assd <- catch.df2[catch.df2$Unassd != 'Unassigned' ,c('trapVisitID','lifeStage','FinalRun','n.tot','mean.fl','sd.fl')]    # & catch.df2$FinalRun == run.name not sure why we need to restrict to run here
colnames(assd) <- c('trapVisitID','lifeStage','FinalRun','n.Orig','mean.fl.Orig','sd.fl.Orig')
catch.dfA <- merge(catch.df1,assd,by=c('trapVisitID','lifeStage','FinalRun'),all.x=TRUE)
# bring in counts of unassigned (unmeasured) fish
unassd <- catch.df2[catch.df2$Unassd == 'Unassigned' ,c('trapVisitID','lifeStage','FinalRun','n.tot')]
colnames(unassd) <- c('trapVisitID','lifeStage','FinalRun','n.Unassd')
catch.df <- merge(catch.dfA,unassd,by=c('trapVisitID','lifeStage','FinalRun'),all.x=TRUE)
runs.found <- unique(catch.df$FinalRun)
runs.found <- runs.found[ !is.na(runs.found) ]
cat("\nRuns found between", min.date, "and", max.date, ":\n")
print(runs.found)
lstages <- unique(catch.df$lifeStage)
lstages <- lstages[ !is.na(lstages) ]   #   Don't need this,  I am pretty sure lifeStage is never missing here.
cat("\nLife stages found between", min.date, "and", max.date, ":\n")
print(lstages)
cat("\n\n")
cat(paste(rep("+",150), collapse="")); cat("\n")
cat("\n\n")
#   ---- Print the number of non-fishing periods
cat( paste("\nNumber of non-fishing intervals at all traps:", sum(visit.df$TrapStatus == "Not fishing"), "\n\n"))
#   ---- Compute passage
output.fn <- output.file
setWinProgressBar( progbar, getWinProgressBar(progbar)*.7 + .3, label="Computing passage" )
cat(paste(rep("*",80), collapse=""))
tmp.mess <- paste("Processing run", run, "-", run.name)
cat(paste("\n", tmp.mess, "\n"))
cat(paste(rep("*",80), collapse=""))
cat("\n\n")
barinc <- 1 / (length(lstages) * 6)
assign( "progbar", progbar, pos=.GlobalEnv )
indRun <- (catch.df$FinalRun == run.name ) & !is.na(catch.df$FinalRun)   # Don't need is.na clause.  FinalRun is never missing here.
catch.df.ls <- catch.df[ indRun , c("trapVisitID", "FinalRun", "lifeStage", 'n.Orig','mean.fl.Orig','sd.fl.Orig',"n.tot", "mean.fl", "sd.fl","n.Unassd")]     # jason 4/14/2015 - n.Orig col added in. 5/20/15 - n.Unassd added
#         catch.df.ls <- catch.df[ indRun , c("trapVisitID", "FinalRun", "lifeStage", "includeCatchID", "n.tot", "mean.fl", "sd.fl")]
#   ---- Merge in the visits to get zeros
catch.df.ls <- merge( visit.df, catch.df.ls, by="trapVisitID", all.x=T )
setWinProgressBar( progbar, getWinProgressBar(progbar)+barinc )
#   ---- Update the constant variables.  Missing n.tot when trap was fishing should be 0.
catch.df.ls$FinalRun[ is.na(catch.df.ls$FinalRun) ] <- run
catch.df.ls$lifeStage <- "All"
catch.df.ls$n.tot[ is.na(catch.df.ls$n.tot) & (catch.df.ls$TrapStatus == "Fishing") ] <- 0
catch.df.ls$n.Orig[ is.na(catch.df.ls$n.Orig) & (catch.df.ls$TrapStatus == "Fishing") ] <- 0
catch.df.ls$n.Unassd[ is.na(catch.df.ls$n.Unassd) & (catch.df.ls$TrapStatus == "Fishing") ] <- 0
#   ---- Compute passage
out.fn.root <- paste0(output.file, "_", run.name )
catch.df.sites <- unique(catch.df[,c('trapPositionID','TrapPosition')])                     # jason add
colnames(catch.df.sites) <- c('subSiteID','subSiteName')                                    # jason add
#catch.df$n.Orig <- ifelse(is.na(catch.df$n.Orig) & catch.df$TrapStatus == 'Fishing',0,catch.df$n.Orig)   # jason add -- 4/15/2015 delete 5/20/2015.  do with other 0 overwrite in passage.R
time.zone <- get("time.zone", env=.GlobalEnv )
f.banner <- function( x ){
cat("\n")
cat(paste(rep("=",50), collapse=""));
cat(x);
cat(paste(rep("=",50), collapse=""));
cat("\n")
}
f.banner(" F.est.passage - START ")
#   This keeps track of the files produced
out.fn.list <- NULL
#   retrieve the progress bar
usepb <- exists( "progbar", where=.GlobalEnv )
# jason add: this data frame has the raw unmarked counts of catch.  note that rows with missing data for certain days, i.e., for which imputation
# occurs also appear as line items here.  so, to get catch, for different trapPositionID/subSiteID, summarise and add togeter (b/c some
# days have more than one record).  brings back more dates than ultimately wanted; let merge below (after grand.df) take care of which
# to keep.
jason.catch2.df <- catch.df[,c('trapVisitID','batchDate','trapPositionID','n.Orig')]
jason.catch3.df <- data.frame(with(jason.catch2.df,tapply(n.Orig, list(batchDate,trapPositionID), sum, na.rm=T )))
jason.catch4.df <- na.omit(reshape(jason.catch3.df,idvar='batchDate',ids=row.names(jason.catch3.df),times=names(jason.catch3.df),timevar='trapPositionID',varying=list(names(jason.catch3.df)),direction='long'))
colnames(jason.catch4.df)[2] <- 'rawCatch'
jason.catch4.df$trapPositionID <- as.character(substr(jason.catch4.df$trapPositionID,2,nchar(jason.catch4.df$trapPositionID)))
jason.catch4.df$batchDate <- as.POSIXct(jason.catch4.df$batchDate,time.zone)
# jason 4/15/2015, do the same thing as above, but with n.tot.  sloppy to do this twice like this, but i know the above works.
jason.totCatch2.df <- catch.df[,c('trapVisitID','batchDate','trapPositionID','n.tot')]
jason.totCatch3.df <- data.frame(with(jason.totCatch2.df,tapply(n.tot, list(batchDate,trapPositionID), sum, na.rm=T )))
jason.totCatch4.df <- na.omit(reshape(jason.totCatch3.df,idvar='batchDate',ids=row.names(jason.totCatch3.df),times=names(jason.totCatch3.df),timevar='trapPositionID',varying=list(names(jason.totCatch3.df)),direction='long'))
colnames(jason.totCatch4.df)[2] <- 'inflatedCatch'
jason.totCatch4.df$trapPositionID <- as.character(substr(jason.totCatch4.df$trapPositionID,2,nchar(jason.totCatch4.df$trapPositionID)))
jason.totCatch4.df$batchDate <- as.POSIXct(jason.totCatch4.df$batchDate,time.zone)
#   ------------------------------------------------------------------
#   Estimate capture for every day of season.  Return value is
#   data frame with columns $batchDate and $catch.
#   By default, this produces one graph in a pdf.  Turn this off with plot=F in call.
#       catch.and.fits has components $catch, $fits, $X.miss, $gaps, $bDates.miss, and $trapsOperating
catch.and.fits <- F.est.catch( catch.df, plot=TRUE, plot.file=file.root )
if(usepb){
progbar <- get( "progbar", pos=.GlobalEnv )
tmp <- getWinProgressBar(progbar)
setWinProgressBar(progbar, (2*tmp + 1)/3 )
}
catch <- catch.and.fits$catch
# the catch dataframe in this list has the imputed values already overwriting the original numbers
jason.catch.and.fits2.df <- catch.and.fits$true.imp
jason.catch.and.fits3.df <- data.frame(with(jason.catch.and.fits2.df,tapply(n.tot, list(batchDate,trapPositionID), sum, na.rm=T )))
jason.catch.and.fits4.df <- na.omit(reshape(jason.catch.and.fits3.df,idvar='batchDate',ids=row.names(jason.catch.and.fits3.df),times=names(jason.catch.and.fits3.df),timevar='trapPositionID',varying=list(names(jason.catch.and.fits3.df)),direction='long'))
colnames(jason.catch.and.fits4.df)[2] <- 'ImputedCatch'
jason.catch.and.fits4.df$trapPositionID <- as.character(substr(jason.catch.and.fits4.df$trapPositionID,2,nchar(jason.catch.and.fits4.df$trapPositionID)))
jason.catch.and.fits4.df$batchDate <- as.POSIXct(jason.catch.and.fits4.df$batchDate,time.zone)
out.fn.list <- c(out.fn.list, attr(catch.and.fits, "out.fn.list"))
#catch.fits <- catch.and.fits$fits  # fits are needed for variance computation
#print(catch[1:20,])
#   ------------------------------------------------------------------
#   Estimate trap efficiency for every batchDate of season.  Return value is
#   data frame with columns $batchDate and $eff.
#   If plot=T, this produces a graph in a pdf.
f.banner(" Efficiency estimation ")
bd <- sort( unique(catch$batchDate) )
eff.and.fits <- F.est.efficiency( release.df, bd, method=3, df=3, plot=TRUE, plot.file=file.root )
if(usepb){
tmp <- getWinProgressBar(progbar)
setWinProgressBar(progbar, (2*tmp + 1)/3 )
}
efficiency <- eff.and.fits$eff
out.fn.list <- c(out.fn.list, attr(eff.and.fits, "out.fn.list"))
if( all(is.na(efficiency[1,])) ){
#   Something is wrong with efficiency data. Make an empty efficiency data frame
efficiency <- data.frame( trapPositionID=catch$trapPositionID, batchDate=catch$batchDate, efficiency=rep(NA, nrow(catch)))
warning("Zero efficiency")
}
#   could do this n <- data.base( catch, efficiency=efficiency$efficiency, gam.estimated.eff=efficiency$gam.estimated )
#   to produce a data frame of values that go into estimator, one line per batchDate
#   ------------------------------------------------------------------
#   Now, estimate passage
if( any(ind <- !is.na(efficiency$efficiency) & (efficiency$efficiency <= 0)) ){    # shouldn't happen that efficiency <= 0, but just in case.  This also gives us a way to exclude days (just set efficiency <= 0)
efficiency$efficiency[ind] <- NA
}
#   First merge catch and efficiency data frames
catch$batchDay <- format(catch$batchDate, "%Y-%m-%d")
catch$trapPositionID <- as.character(catch$trapPositionID)
efficiency$batchDay <- format(efficiency$batchDate, "%Y-%m-%d")
efficiency$trapPositionID <- as.character(efficiency$trapPositionID)
efficiency <- efficiency[,names(efficiency) != "batchDate"]  # drop POSIX date from efficiency
cat("First 20 rows of CATCH...\n")
print(catch[1:20,])
cat("First 20 rows of EFFICIENCY...\n")
print(efficiency[1:20,])
##   Add a trapFunctioning column so can tell when traps start and stop.
#print(catch[1:10,])
#print(catch.and.fits$trapsOperating[1:10,])
#
#catch <- merge( catch, catch.and.fits$trapsOperating, by=c("trapPositionID","batchDate") )
#
#tmp.catch <<- catch
#   The Grand Merge.  Merge catch info with efficiency info.
grand.df <- merge( catch, efficiency, by=c("trapPositionID", "batchDay"), all=T)
#   For each trap, drop the dates that are outside it's start and stop date.  This
#   The season for each trap is identified as non missing catch.  I.e., the grand merge puts
#   in every date because efficiency data frame has all dates.
grand.df <- grand.df[!is.na(grand.df$catch), ]
grand.df.rawCatch <- merge(grand.df,jason.catch4.df,by=c('trapPositionID','batchDate'),all.x=TRUE)                                   # bring in raw catch (measured)
grand.df.rawCatch.Inflated <- merge(grand.df.rawCatch,jason.totCatch4.df,by=c('trapPositionID','batchDate'),all.x=TRUE)                 # bring in inflated catch (measured + plus counts)
grand.df.rawCatch.Imputed <- merge(grand.df.rawCatch.Inflated ,jason.catch.and.fits4.df,by=c('trapPositionID','batchDate'),all.x=TRUE)  # bring in imputed catch
grand.df <- grand.df.rawCatch.Imputed
# somewhere, there are comments that state that catches of NA mean zero.  so, replace NA in each of
# rawCatch and ImputedCatch with zero.
grand.df$assignedCatch <- ifelse(is.na(grand.df$rawCatch), 0, grand.df$rawCatch)
grand.df$inflatedCatch <- ifelse(is.na(grand.df$inflatedCatch), 0, grand.df$inflatedCatch)
grand.df$unassignedCatch <- ifelse(is.na(grand.df$UnassdCatch), 0, grand.df$UnassdCatch)
grand.df$imputedCatch <- ifelse(is.na(grand.df$ImputedCatch), 0, round(grand.df$ImputedCatch,1))
grand.df$totalCatch <- ifelse(is.na(grand.df$inflatedCatch + grand.df$imputedCatch), 0, round(grand.df$inflatedCatch + grand.df$imputedCatch,1))
grand.df$rawCatch <- grand.df$ImputedCatch <- grand.df$catch <- grand.df$UnassdCatch <- NULL
# check and make sure that assignedCatch + unassignedCatch + imputedCatch = totalCatch
# check and make sure that assignedCatch + unassignedCatch = inflatedCatch
# check and make sure that inflatedCatch + imputedCatch = totalCatch
grand.df$sum1 <- grand.df$assignedCatch + grand.df$unassignedCatch + grand.df$imputedCatch
grand.df$sum2 <- grand.df$assignedCatch + grand.df$unassignedCatch
grand.df$sum3 <- grand.df$inflatedCatch + grand.df$imputedCatch
grand.df$check1 <- ifelse(grand.df$sum1 == grand.df$totalCatch,TRUE,FALSE)
grand.df$check2 <- ifelse(grand.df$sum2 == grand.df$inflatedCatch,TRUE,FALSE)
grand.df$check3 <- ifelse(grand.df$sum3 == grand.df$totalCatch,TRUE,FALSE)
if(sum(grand.df$check1 + grand.df$check2 + grand.df$check3) != nrow(grand.df)*3){
stop('Issue with summation of assignedCatch, unassignedCatch, inflatedCatch, imputedCatch, and/or totalCatch.  Investigate est_passage.R, around line 176.')
} else {
cat('No issue with summation of assignedCatch, unassignedCatch, inflatedCatch, imputedCatch, and/or totalCatch.  Continuing...\n')
}
#   The passage estimator
grand.df$passage <- rep(NA, nrow(grand.df))
grand.df$passage <- grand.df$totalCatch / grand.df$efficiency
grand.df$passage <- round(grand.df$passage,1)   # round final passage estimate here so different summaries sum to the same number.
#   Save grand.df to .GlobalEnv (for debuggin) and write it out to a csv file
# catch.df <<- catch
# grand.df <<- grand.df
cat("grand.df stored in .GlobalEnv\n")
if( !is.na(file.root) ){
tmp.df <- grand.df[, !(names(grand.df) %in% c("nReleased", "nCaught", "batchDay")) ]  # do this so can change names (headers) in csv file, Drop 2 columns
names(tmp.df)[ names(tmp.df) == "imputed.catch" ] <- "propImputedCatch"
names(tmp.df)[ names(tmp.df) == "imputed.eff" ] <- "propImputedEff"
tmp.df$propImputedEff <- as.numeric(tmp.df$propImputedEff)  # convert to numbers, 0 or 1
tmp.df$passage <- round(tmp.df$passage)  # Round off passage
tmp.df$totalCatch <- round(tmp.df$totalCatch,1)
tmp.df$efficiency <- round(tmp.df$efficiency, 4)
# Merge in subsiteNames
# ssiteNames <- attr(catch, "subsites")    # jason turn off
ssiteNames <- catch.df.sites               # jason turn on
tmp.df <- merge( ssiteNames, tmp.df, by.x="subSiteID", by.y="trapPositionID", all.y=T )
out.fn <- paste(file.root, "_baseTable.csv", sep="")
tmp.df$TrapPosition <- tmp.df$TrapPositionID <- NULL
#tmp.df$includeCatchID <- ifelse(is.na(tmp.df$includeCatchID),NA,ifelse(tmp.df$includeCatchID == 1,'Yes',ifelse(tmp.df$includeCatchID == 12,'Yes+No','No')))
tmp.df <- tmp.df[c('subSiteID','subSiteName','batchDate','assignedCatch','unassignedCatch','imputedCatch','totalCatch','propImputedCatch','efficiency','propImputedEff','passage')]    # rearrange columns
write.table( tmp.df, file=out.fn, sep=",", row.names=FALSE, col.names=TRUE)
out.fn.list <- c(out.fn.list, out.fn)
}
# ====== Passage estimates are done by day.  Compute variance and summarize ====================================================================================================
f.banner(paste(" Bootstrapping, if called for, and summarizing by", summarize.by))
n <- F.bootstrap.passage( grand.df, catch.and.fits$fits, catch.and.fits$X.miss, catch.and.fits$gaps,
catch.and.fits$bDates.miss, eff.and.fits$fits, eff.and.fits$X, eff.and.fits$ind.inside,
eff.and.fits$X.dates, summarize.by, 100, ci )
if(usepb){
tmp <- getWinProgressBar(progbar)
setWinProgressBar(progbar, tmp + (1-tmp)*.9 )
}
index.aux <- F.summarize.index( catch.df$batchDate, summarize.by )
# jason: for some reason, for testi = 7, bootstrap passage brings back one year, but summarize index brings back
# another, when calculating per year.  this messes up the join below. force the two to be the
# same in this one case.
if(summarize.by == 'year'){
n[1,1] <- index.aux[[1]][1]
}
#   Mean Forklength
num <- catch.df$mean.fl.Orig * catch.df$n.Orig
num <- tapply( num, index.aux, sum, na.rm=T )
#   SD of Forklength
num.sd <- (catch.df$sd.fl.Orig * catch.df$sd.fl.Orig) * (catch.df$n.Orig  - 1)    # this is sum of squares -- well, without the summing just yet
num.sd <- tapply( num.sd, index.aux, sum, na.rm=T )
#   n
den <- tapply( catch.df$n.Orig, index.aux, sum, na.rm=T)
#   Mean and SD computations
aux.fl <- ifelse( den > 0, num / den, NA )
aux.sd <- ifelse( den > 1, sqrt(num.sd / (den-1)), NA )
catch.df.reduced <- aggregate(catch.df,by=list(ID=catch.df$batchDate),head,1)  # 6/5/2015 - jason reduces df to select first of each and changes to batchdate...
catch.df.Fishing <- catch.df
catch.df.Fishing$SampleMinutes <- ifelse(catch.df.Fishing$TrapStatus == 'Not fishing',0,catch.df.Fishing$SampleMinutes)
catch.df.Fishing <- unique(catch.df.Fishing[,c('SampleMinutes','batchDate','trapPositionID')])
num <-  aggregate(catch.df.Fishing$SampleMinutes,by=list(ID=catch.df.Fishing$batchDate),sum)[,2]
#   Amount of time sampled
# if(summarize.by == "day"){
#   catch.df.reduced <- aggregate(catch.df,by=list(ID=catch.df$batchDate),head,1)  # 6/5/2015 - jason reduces df to select first of each and changes to batchdate...
#   catch.df.Fishing <- catch.df
#   catch.df.Fishing$SampleMinutes <- ifelse(catch.df.Fishing$TrapStatus == 'Not fishing',0,catch.df.Fishing$SampleMinutes)
#   catch.df.Fishing <- unique(catch.df.Fishing[,c('SampleMinutes','batchDate','trapPositionID')])
#   num <-  aggregate(catch.df.Fishing$SampleMinutes,by=list(ID=catch.df.Fishing$batchDate),sum)[,2]
# } else {
#   catch.df.reduced <- aggregate(catch.df,by=list(ID=catch.df$trapVisitID),head,1)  # 4/13/2015 - jason reduces df to select first of each
#   num <- as.numeric( catch.df.reduced$SampleMinutes )                                   # 4/13/2015 - jason pulls from reduced df
# }
tzn <- get("time.zone", .GlobalEnv )                                                   # batchDate defaults to mountain time. fix that.
catch.df.reduced$batchDate <- as.POSIXct( strptime( format(catch.df.reduced$batchDate, "%Y-%m-%d"), "%Y-%m-%d", tz=tzn),tz=tzn)   # fix the time.
index.aux <- F.summarize.index(catch.df.reduced$batchDate,summarize.by)               # 4/13/2015 - jason indexes in reduced df
aux.hrs <- tapply( num, index.aux, sum, na.rm=T )/60                                  # this is hours actually sampled during the 'index' period
#den <- rep( 24, length(batchDate.filled) )
#den <- tapply( den, index.aux2, sum, na.rm=T )  # this is total hours in 'index' period
#
#   Note: I will leave the commented out code that computes amount of time in each index period.  The reason
#   I commented it out is that 'den' may have more rows than num.  i.e., catch.df$batchDate may have fewer rows than batchDate.filled.
#   This makes 'den' difficult to merge back in to 'num', but it could be done.
aux<-data.frame( s.by=dimnames(aux.fl)[[1]],
nForkLenMM=c(den),
meanForkLenMM=c(aux.fl),
sdForkLenMM=c(aux.sd),
sampleLengthHrs=c(aux.hrs),
stringsAsFactors=F, row.names=NULL )
#   ---- Merge 'n' and 'aux' information together
n <- merge(n,aux, by="s.by", all.x=T)
n$sampleLengthDays <- n$sampleLengthHrs / 24
tz.offset <- as.numeric(as.POSIXct(0, origin="1970-01-01", tz=time.zone))
n$date <- as.POSIXct( n$date-tz.offset, origin="1970-01-01", tz=time.zone )  # I think this only works west of GMT (North America).  East of GMT, it may be 12 hours off. UNTESTED east of GMT
#   Put the final data frame together
names(n)[names(n) == "s.by"] <- summarize.by
attr(n, "taxonID" ) <- attr(catch.df,"taxonID")
attr(n, "species.name") <- attr(catch.df, "species.name")
attr(n, "siteID" ) <- attr(catch.df,"siteID")
attr(n, "site.name") <- attr(catch.df, "site.name")
attr(n, "site.abbr") <- attr(catch.df, "site.abbr")
attr(n, "runID") <- attr(catch.df, "runID")
attr(n, "run.name") <- attr(catch.df, "run.name")
attr(n, "year") <- attr(catch.df, "year")
attr(n, "run.season") <- attr(catch.df, "run.season")
attr(n, "summarized.by") <- summarize.by
attr(n, "out.fn.list") <- out.fn.list
attr(n, "trapsOperating") <- catch.and.fits$trapsOperating
f.banner(" F.est.passage - COMPLETE ")
output.file  <- paste0("..//Outputs//",river,"_",siteText,"_",min.date,"_",max.date)
output.file
F.run.passage     ( site, taxon,      min.date, max.date, by=by,        output.file=output.file,                     ci=TRUE            )
close(db)
close(ch)
ch
close(ch)
stop
odbcClose(ch)
ch
close(ch)
close(ch)
close(ch)
