<<<<<<< HEAD
ind <- (catch.df$StartTime <= sunset) & (sunrise > catch.df$EndTime)
catch.df$night[ind] <- 1
catch.df$pct.night[ind] <- (as.numeric(catch.df$EndTime[ind]) - as.numeric(sunset[ind])) / (as.numeric(sunrise[ind]) - as.numeric(sunset[ind]))
ind <- (catch.df$sampleStart > sunset) & (sunrise <= catch.df$EndTime)
catch.df$night[ind] <- 1
catch.df$pct.night[ind] <- (as.numeric(sunrise[ind]) - as.numeric(catch.df$StartTime[ind])) / (as.numeric(sunrise[ind]) - as.numeric(sunset[ind]))
catch.df
library(splines)
#catch.df <- catch.df[ catch.df$TrapStatus == "Fishing", ]
catch.df$log.sampleLengthHrs <- log(as.numeric( catch.df$SampleMinutes/60 ))
p.night <- sum(catch.df$night) / nrow(catch.df)
p.night
glm( n.tot ~ offset(log.sampleLengthHrs) , family=poisson, data=catch.df )
catch.df <- df2
#   Sort the data frame properly, by trapPosition and date of visit
#   This puts the gaps in their correct locations
catch.df <- catch.df[ order(catch.df$trapPositionID, catch.df$EndTime), ]
#   Compute the "night" variables.
time.zone <- get("time.zone", env=.GlobalEnv )
sunset  <- as.POSIXct( paste(format(catch.df$StartTime, "%Y-%m-%d"), "19:00:00"), format="%Y-%m-%d %H:%M:%S", tzone=time.zone )
sunrise <- as.POSIXct( paste(format(catch.df$EndTime, "%Y-%m-%d"), "07:00:00"), format="%Y-%m-%d %H:%M:%S", tzone=time.zone )
catch.df$night <- 0
catch.df$pct.night <- 0
ind <- (catch.df$StartTime <= sunset) & (sunrise <= catch.df$EndTime)
catch.df$night[ind] <- 1
catch.df$pct.night[ind] <- 1
ind <- (catch.df$StartTime <= sunset) & (sunrise > catch.df$EndTime)
catch.df$night[ind] <- 1
catch.df$pct.night[ind] <- (as.numeric(catch.df$EndTime[ind]) - as.numeric(sunset[ind])) / (as.numeric(sunrise[ind]) - as.numeric(sunset[ind]))
ind <- (catch.df$sampleStart > sunset) & (sunrise <= catch.df$EndTime)
catch.df$night[ind] <- 1
catch.df$pct.night[ind] <- (as.numeric(sunrise[ind]) - as.numeric(catch.df$StartTime[ind])) / (as.numeric(sunrise[ind]) - as.numeric(sunset[ind]))
#   Fit a rate model.
library(splines)
#catch.df <- catch.df[ catch.df$TrapStatus == "Fishing", ]
catch.df$log.sampleLengthHrs <- log(as.numeric( catch.df$SampleMinutes/60 ))
p.night <- sum(catch.df$night) / nrow(catch.df)
#   Fit null model.  The gap catches are NA here, so they are dropped from the fit.  Later, they are replaced.
if( p.night < 0.9 ){
fit <- glm( n.tot ~ offset(log.sampleLengthHrs)  + night, family=poisson, data=catch.df )
} else {
fit <- glm( n.tot ~ offset(log.sampleLengthHrs) , family=poisson, data=catch.df )
}
fit.AIC <- AIC(fit)
#tmp.cc <<- catch.df   # print( tmp.cc[,c(1,3,4,5,6,7,10,18)] )
#   Fit glm model, increasing df, until the model goes bad
cat(paste("Number of non-zero catches : ", sum(!is.na(catch.df$n.tot) & (catch.df$n.tot > 0)), "\n"))
cat("Catch model fitting:\n")
cat(paste("df= ", 0, ", conv= ", fit$converged, " bound= ", fit$boundary, " AIC= ", round(fit.AIC, 4), "\n"))
sum(!is.na(catch.df$n.tot) & (catch.df$n.tot > 0))
dim(catch.df)
cur.df <- 1
repeat{
if( cur.df == 1 ){
j <- as.numeric( format(catch.df$EndTime, "%j"))
bs.sEnd <- matrix(j,ncol=1)
} else if( cur.df == 2 ){
j <- as.numeric( format(catch.df$EndTime, "%j"))
bs.sEnd <- cbind(Lin=j, Quad=j*j)
} else {
bs.sEnd <- bs( catch.df$EndTime, df=cur.df )
}
if( p.night < 0.9 ){
cur.fit <- glm( n.tot ~ offset(log.sampleLengthHrs) + bs.sEnd + night, family=poisson, data=catch.df )
} else {
cur.fit <- glm( n.tot ~ offset(log.sampleLengthHrs) + bs.sEnd, family=poisson, data=catch.df )
}
cur.AIC <- AIC( cur.fit )
cat(paste("df= ", cur.df, ", conv= ", cur.fit$converged, " bound= ", cur.fit$boundary, " AIC= ", round(cur.AIC, 4), "\n"))
if( !cur.fit$converged | cur.fit$boundary | cur.df > 15 | cur.AIC > (fit.AIC - 2) ){
break
} else {
fit <- cur.fit
fit.AIC <- cur.AIC
bs.sampleEnd <- bs.sEnd
cur.df <- cur.df + 1
}
}
catch.df$EndTime
cur.df
bs.sEnd <- bs( catch.df$EndTime, df=cur.df )
p.nighty
p.night
n.tot
glm( n.tot ~ offset(log.sampleLengthHrs) + bs.sEnd, family=poisson, data=catch.df )
catch.df$n.tot
catch.df$log.sampleLengthHrs
bs.sEnd
r <- c(1,2,3,4,3,2,3,2,3)
s <- c(7,7,6,7,NA,6,7,6,7)
glm(r ~ s,family=poisson)
catch.df$n.tot
catch.df$sampleLengthHrs
head(catch.df)
catch.df[,c('SampleMinutes','log.sampleLengthHrs')]
catch.df[,c('n.tot','SampleMinutes','log.sampleLengthHrs')]
glm( n.tot ~ offset(log.sampleLengthHrs) , family=poisson, data=catch.df )
bs.sEnd
help(bs)
cur.fit <- glm( n.tot ~ offset(log.sampleLengthHrs) + bs.sEnd, family=poisson, data=catch.df )
glm( n.tot ~ offset(log.sampleLengthHrs) + bs.sEnd + night, family=poisson, data=catch.df )
help(glm)
help(glm.control)
glm( n.tot ~ offset(log.sampleLengthHrs) + bs.sEnd, family=poisson, data=catch.df, glm.control(trace=TRUE))
glm( n.tot ~ offset(log.sampleLengthHrs) + bs.sEnd, family=poisson, data=catch.df, trace=TRUE)
head(catch.df)
glm( n.tot ~ offset(log.sampleLengthHrs) + bs.sEnd, family=poisson, data=catch.df, trace=TRUE)
head(bs.sEnd)
getwd()
save.image("weirdGLM.RData")
dataDir <- "//LAR-FILE-SRV/Data/Jason/sage grouse/Data"
progDir <- "//LAR-FILE-SRV/Data/Jason/sage grouse/Programs"
origDir <- paste0(dataDir,"/Original")
source(paste0(progDir,"/prepareForAnalysis.R"))
sg <- read.csv(paste0(origDir,"/allStatesFinal.csv"))
river        <- 'Feather'#'american'
site         <- 4000#57000
siteText     <- 'testing'
run          <- 3
runText      <- 'Fall'
#       min.date     <- "2013-10-01"
#       max.date     <- "2014-09-29"
min.date <- "2000-11-26"
max.date <- "2001-07-23"
#   ********
#   Check that times are less than 1 year apart
strt.dt <- as.POSIXct( min.date, format="%Y-%m-%d" )
end.dt <- as.POSIXct( max.date, format="%Y-%m-%d" )
run.season <- data.frame( start=strt.dt, end=end.dt )
dt.len <- difftime(end.dt, strt.dt, units="days")
if( dt.len > 366 )  stop("Cannot specify more than 365 days in F.passage. Check min.date and max.date.")
#   ---- Fetch efficiency data
release.df <- F.get.release.data( site, taxon, min.date, max.date  )
if( nrow(release.df) == 0 ){
stop( paste( "No efficiency trials between", min.date, "and", max.date, ". Check dates."))
}
#   ---- Fetch the catch and visit data
tmp.df   <- F.get.catch.data( site, taxon, min.date, max.date  )
catch.df <- tmp.df$catch   # All positive catches, all FinalRun and lifeStages, inflated for plus counts.  Zero catches (visits without catch) are NOT here.
visit.df <- tmp.df$visit   # the unique trap visits.  This will be used in a merge to get 0's later
catch.dfX <- catch.df      # save for a small step below.  several dfs get named catch.df, so need to call this something else.
#   Debugging
#    tmp.catch0 <<- catch.df
#    tmp.visit0 <<- visit.df
#    print( table(catch.df$TrapStatus))
if( nrow(catch.df) == 0 ){
stop( paste( "No catch records between", min.date, "and", max.date, ". Check dates and taxon."))
}
#   ---- Summarize catch data by trapVisitID X FinalRun X lifeStage. Upon return, catch.df has one line per combination of these variables
#catch.df <- F.summarize.fish.visit( catch.df )       jason turns off 4/15/2015
catch.df0 <- F.summarize.fish.visit( catch.df, 'unassigned' )   # jason - 5/20/2015 - we summarize over lifeStage, wrt to unassigned.
catch.df1 <- F.summarize.fish.visit( catch.df, 'inflated' )     # jason - 4/14/2015 - we summarize over lifeStage, w/o regard to unassigned.  this is what has always been done.
catch.df2 <- F.summarize.fish.visit( catch.df, 'assigned')      # jason - 4/14/2015 - we summarize over assigned.  this is new, and necessary to break out by MEASURED, instead of CAUGHT.
#                   - the only reason we do this again is to get a different n.tot.
#   Debugging
#    tmp.catch <<- catch.df
#    print( table(catch.df$TrapStatus))
#    cat("in lifestage_passage.r (hit return) ")
#    readline()
#   ---- Compute the unique runs we need to do
runs <- unique(c(catch.df1$FinalRun,catch.df2$FinalRun))    # get all instances over the two df.  jason change 4/17/2015 5/21/2015: don't think we need to worry about catch.df0.
runs <- runs[ !is.na(runs) ]
cat("\nRuns found between", min.date, "and", max.date, ":\n")
print(runs)
#   ---- Compute the unique life stages we need to do
lstages <- unique(c(catch.df1$lifeStage,catch.df2$lifeStage))   # get all instances over the two df.  jason change 4/17/2015 5/21/2015: don't think we need to worry about catch.df0.
lstages <- lstages[ !is.na(lstages) ]   #   Don't need this,  I am pretty sure lifeStage is never missing here.
cat("\nLife stages found between", min.date, "and", max.date, ":\n")
print(lstages)
#   ---- Print the number of non-fishing periods
cat( paste("\nNumber of non-fishing intervals at all traps:", sum(visit.df$TrapStatus == "Not fishing"), "\n\n"))
#   ---- Extract the unique trap visits.  This will be used in merge to get 0's later
#    ind <- !duplicated( catch.df$trapVisitID ) & !is.na(catch.df$trapVisitID)
#    visit.df <- catch.df[ind, ]
#    visit.df <- visit.df[, !(names(visit.df) %in% c("FinalRun", "lifeStage", "n.tot", "mean.fl", "sd.fl"))]
#   ********
#   Loop over runs
ans <- lci <- uci <- matrix(0, length(lstages), length(runs))
dimnames(ans)<-list(lstages, runs)
out.fn.roots <- NULL
j <- 1
i <- 1
ls <- lstages[i]
#   ---- Subset to just one life stage and run
indLS <- (catch.df$lifeStage == ls) & !is.na(catch.df$lifeStage) #  Don't need is.na clause.  I don't think lifeStage can be missing here.
cat(paste("Lifestage=", ls, "; Run=", run.name, "; num records=", sum(indRun & indLS), "\n"))
tmp.mess <- paste("Lifestage=", ls )
setWinProgressBar( progbar, getWinProgressBar(progbar)+barinc, label=tmp.mess )
strt.dt
end.dt
dim(catch.dfX)
=======
png(filename=paste0(grousePath,'/Results/GrouseCentroids.png',sep=""),width=9,height=6.5,units="in",res=300)
plot(grouseShp)
plot(grouseShp,xlim=c(xmin,xmax),ylim=c(ymin,ymax))
points(grouseShp@data$x,grouseShp@data$y,xlim=c(xmin,xmax),ylim=c(ymin,ymax),col='red',pch=19)
dev.off()
writeOGR(grouseShp,paste0(grousePath,'/Results'),'grouseCentroided',driver="ESRI Shapefile",overwrite_layer=TRUE)
hmm <- spTransform(grouseShp, CRS(projLatLong))
projLatLong  <- "+init=epsg:4326"
hmm <- spTransform(grouseShp, CRS(projLatLong))
hmm@data
grouseShpLatLon <- spTransform(grouseShp, CRS(projLatLong))
class(grouseShpLatLon)
slotNames(grouseShpLatLong)
slotNames(grouseShpLatLon)
grouseShpLatLong@proj4string
grouseShpLatLon@proj4string
grouseShp@proj4string
# read in the data and add in the centroids
grouseShp <- readOGR(paste0(grousePath,'/Data'),grousePoly);
grouseShp@data <- cbind(grouseShp@data,data.frame(gCentroid(grouseShp,byid=TRUE,id=NULL)@coords))
grouseShpLatLon <- spTransform(grouseShp, CRS(projLatLong))
grouseShpLatLon@data <- cbind(grouseShpLatLon@data,data.frame(gCentroid(grouseShpLatLon,byid=TRUE,id=NULL)@coords))
grouseShpLatLon@data
require(rgdal)          # for reading and writing shapefiles
require(rgeos)          # for function gCentroid
# setup stuff
grousePath <- '\\\\LAR-FILE-SRV/Data/C. LeBeau/CentroidingGrouse'
grousePoly <- 'NHD_grouse_locs_fr_animal_soc'
projLatLong  <- "+init=epsg:4326"
# read in the data and add in the centroids
grouseShp <- readOGR(paste0(grousePath,'/Data'),grousePoly);
grouseShp@data <- cbind(grouseShp@data,data.frame(gCentroid(grouseShp,byid=TRUE,id=NULL)@coords))
grouseShpLatLon <- spTransform(grouseShp, CRS(projLatLong))
grouseShpLatLon@data <- cbind(grouseShpLatLon@data,data.frame(gCentroid(grouseShpLatLon,byid=TRUE,id=NULL)@coords))
# OUTPUT POLY WITH CENTROIDS ON ORIGINAL PROJECTION
# define x and y bounds so as to plot two things (original polygons and centroids) correctly
xmin <- grouseShp@bbox[1,1]
xmax <- grouseShp@bbox[1,2]
ymin <- grouseShp@bbox[2,1]
ymax <- grouseShp@bbox[2,2]
# output a simple plot
png(filename=paste0(grousePath,'/Results/GrouseCentroids.png',sep=""),width=9,height=6.5,units="in",res=300)
plot(grouseShp)
plot(grouseShp,xlim=c(xmin,xmax),ylim=c(ymin,ymax))
points(grouseShp@data$x,grouseShp@data$y,xlim=c(xmin,xmax),ylim=c(ymin,ymax),col='red',pch=19)
dev.off()
# OUTPUT POLY WITH CENTROIDS IN LAT LON
# define x and y bounds so as to plot two things (original polygons and centroids) correctly
xmin <- grouseShpLatLon@bbox[1,1]
xmax <- grouseShpLatLon@bbox[1,2]
ymin <- grouseShpLatLon@bbox[2,1]
ymax <- grouseShpLatLon@bbox[2,2]
# output a simple plot
png(filename=paste0(grousePath,'/Results/GrouseCentroidsLatLon.png',sep=""),width=9,height=6.5,units="in",res=300)
plot(grouseShpLatLon)
plot(grouseShpLatLon,xlim=c(xmin,xmax),ylim=c(ymin,ymax))
points(grouseShpLatLon@data$x,grouseShpLatLon@data$y,xlim=c(xmin,xmax),ylim=c(ymin,ymax),col='red',pch=19)
dev.off()
# write out the updated shapefile in a new place
writeOGR(grouseShp,paste0(grousePath,'/Results'),'grouseCentroided',driver="ESRI Shapefile",overwrite_layer=TRUE)
writeOGR(grouseShpLatLon,paste0(grousePath,'/Results'),'grouseCentroidedLatLon',driver="ESRI Shapefile",overwrite_layer=TRUE)
head(grouseShpLatLon@data)
require(rgdal)          # for reading and writing shapefiles
require(rgeos)          # for function gCentroid
# setup stuff
grousePath <- '\\\\LAR-FILE-SRV/Data/C. LeBeau/CentroidingGrouse'
grousePoly <- 'NHD_grouse_locs_fr_animal_soc'
projLatLong  <- "+init=epsg:4326"
# read in the data and add in the centroids
grouseShp <- readOGR(paste0(grousePath,'/Data'),grousePoly);
grouseShp@data <- cbind(grouseShp@data,data.frame(gCentroid(grouseShp,byid=TRUE,id=NULL)@coords))
names(grouseShp)[names(grouseShp) == 'x'] <- 'xProjected'
names(grouseShp)[names(grouseShp) == 'y'] <- 'yProjected'
grouseShpLatLon <- spTransform(grouseShp, CRS(projLatLong))
grouseShpLatLon@data <- cbind(grouseShpLatLon@data,data.frame(gCentroid(grouseShpLatLon,byid=TRUE,id=NULL)@coords))
names(grouseShpLatLon)[names(grouseShpLatLon) == 'x'] <- 'xLat'
names(grouseShpLatLon)[names(grouseShpLatLon) == 'y'] <- 'yLon'
# OUTPUT POLY WITH CENTROIDS ON ORIGINAL PROJECTION
# define x and y bounds so as to plot two things (original polygons and centroids) correctly
xmin <- grouseShp@bbox[1,1]
xmax <- grouseShp@bbox[1,2]
ymin <- grouseShp@bbox[2,1]
ymax <- grouseShp@bbox[2,2]
# output a simple plot
png(filename=paste0(grousePath,'/Results/GrouseCentroids.png',sep=""),width=9,height=6.5,units="in",res=300)
plot(grouseShp)
plot(grouseShp,xlim=c(xmin,xmax),ylim=c(ymin,ymax))
points(grouseShp@data$x,grouseShp@data$y,xlim=c(xmin,xmax),ylim=c(ymin,ymax),col='red',pch=19)
dev.off()
# OUTPUT POLY WITH CENTROIDS IN LAT LON
# define x and y bounds so as to plot two things (original polygons and centroids) correctly
xmin <- grouseShpLatLon@bbox[1,1]
xmax <- grouseShpLatLon@bbox[1,2]
ymin <- grouseShpLatLon@bbox[2,1]
ymax <- grouseShpLatLon@bbox[2,2]
# output a simple plot
png(filename=paste0(grousePath,'/Results/GrouseCentroidsLatLon.png',sep=""),width=9,height=6.5,units="in",res=300)
plot(grouseShpLatLon)
plot(grouseShpLatLon,xlim=c(xmin,xmax),ylim=c(ymin,ymax))
points(grouseShpLatLon@data$x,grouseShpLatLon@data$y,xlim=c(xmin,xmax),ylim=c(ymin,ymax),col='red',pch=19)
dev.off()
# write out the updated shapefile in a new place
writeOGR(grouseShp,paste0(grousePath,'/Results'),'grouseCentroided',driver="ESRI Shapefile",overwrite_layer=TRUE)
writeOGR(grouseShpLatLon,paste0(grousePath,'/Results'),'grouseCentroidedLatLon',driver="ESRI Shapefile",overwrite_layer=TRUE)
require(rgdal)          # for reading and writing shapefiles
require(rgeos)          # for function gCentroid
# setup stuff
grousePath <- '\\\\LAR-FILE-SRV/Data/C. LeBeau/CentroidingGrouse'
grousePoly <- 'NHD_grouse_locs_fr_animal_soc'
projLatLong  <- "+init=epsg:4326"
# read in the data and add in the centroids
grouseShp <- readOGR(paste0(grousePath,'/Data'),grousePoly);
grouseShp@data <- cbind(grouseShp@data,data.frame(gCentroid(grouseShp,byid=TRUE,id=NULL)@coords))
names(grouseShp)[names(grouseShp) == 'x'] <- 'xProjected'
names(grouseShp)[names(grouseShp) == 'y'] <- 'yProjected'
grouseShpLatLon <- spTransform(grouseShp, CRS(projLatLong))
grouseShpLatLon@data <- cbind(grouseShpLatLon@data,data.frame(gCentroid(grouseShpLatLon,byid=TRUE,id=NULL)@coords))
names(grouseShpLatLon)[names(grouseShpLatLon) == 'x'] <- 'xLat'
names(grouseShpLatLon)[names(grouseShpLatLon) == 'y'] <- 'yLon'
# OUTPUT POLY WITH CENTROIDS ON ORIGINAL PROJECTION
# define x and y bounds so as to plot two things (original polygons and centroids) correctly
xmin <- grouseShp@bbox[1,1]
xmax <- grouseShp@bbox[1,2]
ymin <- grouseShp@bbox[2,1]
ymax <- grouseShp@bbox[2,2]
# output a simple plot
png(filename=paste0(grousePath,'/Results/GrouseCentroids.png',sep=""),width=9,height=6.5,units="in",res=300)
plot(grouseShp)
plot(grouseShp,xlim=c(xmin,xmax),ylim=c(ymin,ymax))
points(grouseShp@data$xProjected,grouseShp@data$yProjected,xlim=c(xmin,xmax),ylim=c(ymin,ymax),col='red',pch=19)
dev.off()
# OUTPUT POLY WITH CENTROIDS IN LAT LON
# define x and y bounds so as to plot two things (original polygons and centroids) correctly
xmin <- grouseShpLatLon@bbox[1,1]
xmax <- grouseShpLatLon@bbox[1,2]
ymin <- grouseShpLatLon@bbox[2,1]
ymax <- grouseShpLatLon@bbox[2,2]
# output a simple plot
png(filename=paste0(grousePath,'/Results/GrouseCentroidsLatLon.png',sep=""),width=9,height=6.5,units="in",res=300)
plot(grouseShpLatLon)
plot(grouseShpLatLon,xlim=c(xmin,xmax),ylim=c(ymin,ymax))
points(grouseShpLatLon@data$xLatLon,grouseShpLatLon@data$yLatLon,xlim=c(xmin,xmax),ylim=c(ymin,ymax),col='red',pch=19)
dev.off()
# write out the updated shapefile in a new place
writeOGR(grouseShp,paste0(grousePath,'/Results'),'grouseCentroided',driver="ESRI Shapefile",overwrite_layer=TRUE)
writeOGR(grouseShpLatLon,paste0(grousePath,'/Results'),'grouseCentroidedLatLon',driver="ESRI Shapefile",overwrite_layer=TRUE)
xmin
xmax
plot(grouseShpLatLon,xlim=c(xmin,xmax),ylim=c(ymin,ymax))
points(grouseShpLatLon@data$xLatLon,grouseShpLatLon@data$yLatLon,xlim=c(xmin,xmax),ylim=c(ymin,ymax),col='red',pch=19)
head(grouseShpLatLong@data)
head(grouseShpLatLon@data)
require(rgdal)          # for reading and writing shapefiles
require(rgeos)          # for function gCentroid
# setup stuff
grousePath <- '\\\\LAR-FILE-SRV/Data/C. LeBeau/CentroidingGrouse'
grousePoly <- 'NHD_grouse_locs_fr_animal_soc'
projLatLong  <- "+init=epsg:4326"
# read in the data and add in the centroids
grouseShp <- readOGR(paste0(grousePath,'/Data'),grousePoly);
grouseShp@data <- cbind(grouseShp@data,data.frame(gCentroid(grouseShp,byid=TRUE,id=NULL)@coords))
names(grouseShp)[names(grouseShp) == 'x'] <- 'xProjected'
names(grouseShp)[names(grouseShp) == 'y'] <- 'yProjected'
grouseShpLatLon <- spTransform(grouseShp, CRS(projLatLong))
grouseShpLatLon@data <- cbind(grouseShpLatLon@data,data.frame(gCentroid(grouseShpLatLon,byid=TRUE,id=NULL)@coords))
names(grouseShpLatLon)[names(grouseShpLatLon) == 'x'] <- 'xLatLon'
names(grouseShpLatLon)[names(grouseShpLatLon) == 'y'] <- 'yLatLon'
# OUTPUT POLY WITH CENTROIDS ON ORIGINAL PROJECTION
# define x and y bounds so as to plot two things (original polygons and centroids) correctly
xmin <- grouseShp@bbox[1,1]
xmax <- grouseShp@bbox[1,2]
ymin <- grouseShp@bbox[2,1]
ymax <- grouseShp@bbox[2,2]
# output a simple plot
png(filename=paste0(grousePath,'/Results/GrouseCentroids.png',sep=""),width=9,height=6.5,units="in",res=300)
plot(grouseShp,xlim=c(xmin,xmax),ylim=c(ymin,ymax))
points(grouseShp@data$xProjected,grouseShp@data$yProjected,xlim=c(xmin,xmax),ylim=c(ymin,ymax),col='red',pch=19)
dev.off()
# OUTPUT POLY WITH CENTROIDS IN LAT LON
# define x and y bounds so as to plot two things (original polygons and centroids) correctly
xmin <- grouseShpLatLon@bbox[1,1]
xmax <- grouseShpLatLon@bbox[1,2]
ymin <- grouseShpLatLon@bbox[2,1]
ymax <- grouseShpLatLon@bbox[2,2]
# output a simple plot
png(filename=paste0(grousePath,'/Results/GrouseCentroidsLatLon.png',sep=""),width=9,height=6.5,units="in",res=300)
plot(grouseShpLatLon,xlim=c(xmin,xmax),ylim=c(ymin,ymax))
points(grouseShpLatLon@data$xLatLon,grouseShpLatLon@data$yLatLon,xlim=c(xmin,xmax),ylim=c(ymin,ymax),col='red',pch=19)
dev.off()
# write out the updated shapefile in a new place
writeOGR(grouseShp,paste0(grousePath,'/Results'),'grouseCentroided',driver="ESRI Shapefile",overwrite_layer=TRUE)
writeOGR(grouseShpLatLon,paste0(grousePath,'/Results'),'grouseCentroidedLatLon',driver="ESRI Shapefile",overwrite_layer=TRUE)
# write out the data alone
write.csv(grouseShp,paste0(grousePath,'/Results/grouseCentroided.csv')
write.csv(grouseShpLatLon,paste0(grousePath,'/Results/grouseCentroidedLatLon.csv')
# write out the data alone
write.csv(grouseShp,paste0(grousePath,'/Results/grouseCentroided.csv'))
write.csv(grouseShpLatLon,paste0(grousePath,'/Results/grouseCentroidedLatLon.csv'))
slotNames(grouseShpLatLon@proj4string)
slotNames(grouseShpLatLon)
grouseShpLatLon@proj4string
# read in the data and add in the centroids
# do it in the projected system
grouseShp <- readOGR(paste0(grousePath,'/Data'),grousePoly);
grouseShp@data <- cbind(grouseShp@data,data.frame(gCentroid(grouseShp,byid=TRUE,id=NULL)@coords))
names(grouseShp)[names(grouseShp) == 'x'] <- 'xProjected'
names(grouseShp)[names(grouseShp) == 'y'] <- 'yProjected'
# do it in lat lon
grouseShpLatLon <- spTransform(grouseShp, CRS(projLatLong))
grouseShpLatLon@data <- cbind(grouseShpLatLon@data,data.frame(gCentroid(grouseShpLatLon,byid=TRUE,id=NULL)@coords))
names(grouseShpLatLon)[names(grouseShpLatLon) == 'x'] <- 'xLatLon'
names(grouseShpLatLon)[names(grouseShpLatLon) == 'y'] <- 'yLatLon'
grouseShpLatLon <- spTransform(grouseShpLatLon, CRS("+init=epsg:4326 +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))
grouseShp <- grouseShpLatLon
# OUTPUT POLY WITH CENTROIDS ON ORIGINAL PROJECTION
# define x and y bounds so as to plot two things (original polygons and centroids) correctly
xmin <- grouseShp@bbox[1,1]
xmax <- grouseShp@bbox[1,2]
ymin <- grouseShp@bbox[2,1]
ymax <- grouseShp@bbox[2,2]
# output a simple plot
png(filename=paste0(grousePath,'/Results/GrouseCentroids.png',sep=""),width=9,height=6.5,units="in",res=300)
plot(grouseShp,xlim=c(xmin,xmax),ylim=c(ymin,ymax))
points(grouseShp@data$xProjected,grouseShp@data$yProjected,xlim=c(xmin,xmax),ylim=c(ymin,ymax),col='red',pch=19)
dev.off()
require(rgdal)          # for reading and writing shapefiles
require(rgeos)          # for function gCentroid
# setup stuff
grousePath <- '\\\\LAR-FILE-SRV/Data/C. LeBeau/CentroidingGrouse'
grousePoly <- 'NHD_grouse_locs_fr_animal_soc'
projLatLong  <- "+init=epsg:4326"
# read in the data and add in the centroids
# do it in the projected system
grouseShp <- readOGR(paste0(grousePath,'/Data'),grousePoly);
grouseShp@data <- cbind(grouseShp@data,data.frame(gCentroid(grouseShp,byid=TRUE,id=NULL)@coords))
names(grouseShp)[names(grouseShp) == 'x'] <- 'xProjected'
names(grouseShp)[names(grouseShp) == 'y'] <- 'yProjected'
# do it in lat lon
grouseShpLatLon <- spTransform(grouseShp, CRS(projLatLong))
grouseShpLatLon@data <- cbind(grouseShpLatLon@data,data.frame(gCentroid(grouseShpLatLon,byid=TRUE,id=NULL)@coords))
names(grouseShpLatLon)[names(grouseShpLatLon) == 'x'] <- 'xLatLon'
names(grouseShpLatLon)[names(grouseShpLatLon) == 'y'] <- 'yLatLon'
grouseShpLatLon <- spTransform(grouseShpLatLon, CRS("+init=epsg:4326 +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))
grouseShp <- grouseShpLatLon
# OUTPUT POLY WITH CENTROIDS ON ORIGINAL PROJECTION
# define x and y bounds so as to plot two things (original polygons and centroids) correctly
xmin <- grouseShp@bbox[1,1]
xmax <- grouseShp@bbox[1,2]
ymin <- grouseShp@bbox[2,1]
ymax <- grouseShp@bbox[2,2]
# output a simple plot
png(filename=paste0(grousePath,'/Results/GrouseCentroids.png',sep=""),width=9,height=6.5,units="in",res=300)
plot(grouseShp,xlim=c(xmin,xmax),ylim=c(ymin,ymax))
points(grouseShp@data$xProjected,grouseShp@data$yProjected,xlim=c(xmin,xmax),ylim=c(ymin,ymax),col='red',pch=19)
dev.off()
# OUTPUT POLY WITH CENTROIDS IN LAT LON
# define x and y bounds so as to plot two things (original polygons and centroids) correctly
# xmin <- grouseShpLatLon@bbox[1,1]
# xmax <- grouseShpLatLon@bbox[1,2]
# ymin <- grouseShpLatLon@bbox[2,1]
# ymax <- grouseShpLatLon@bbox[2,2]
#
# # output a simple plot
# png(filename=paste0(grousePath,'/Results/GrouseCentroidsLatLon.png',sep=""),width=9,height=6.5,units="in",res=300)
#   plot(grouseShpLatLon,xlim=c(xmin,xmax),ylim=c(ymin,ymax))
#   points(grouseShpLatLon@data$xLatLon,grouseShpLatLon@data$yLatLon,xlim=c(xmin,xmax),ylim=c(ymin,ymax),col='red',pch=19)
# dev.off()
# write out the updated shapefile in a new place
writeOGR(grouseShp,paste0(grousePath,'/Results'),'grouseCentroided',driver="ESRI Shapefile",overwrite_layer=TRUE)
# write out the data alone
write.csv(grouseShp,paste0(grousePath,'/Results/grouseCentroided.csv'))
xmin <- grouseShp@bbox[1,1]
xmax <- grouseShp@bbox[1,2]
ymin <- grouseShp@bbox[2,1]
ymax <- grouseShp@bbox[2,2]
xmin
# setup stuff
grousePath <- '\\\\LAR-FILE-SRV/Data/C. LeBeau/CentroidingGrouse'
grousePoly <- 'NHD_grouse_locs_fr_animal_soc'
projLatLong  <- "+init=epsg:4326"
# read in the data and add in the centroids
# do it in the projected system
grouseShp <- readOGR(paste0(grousePath,'/Data'),grousePoly);
grouseShp@proj4string
require(rgdal)          # for reading and writing shapefiles
require(rgeos)          # for function gCentroid
# setup stuff
grousePath <- '\\\\LAR-FILE-SRV/Data/C. LeBeau/CentroidingGrouse'
grousePoly <- 'NHD_grouse_locs_fr_animal_soc'
projLatLong  <- "+init=epsg:4326"
# read in the data and add in the centroids
# do it in the projected system
grouseShp <- readOGR(paste0(grousePath,'/Data'),grousePoly);
grouseShp@data <- cbind(grouseShp@data,data.frame(gCentroid(grouseShp,byid=TRUE,id=NULL)@coords))
names(grouseShp)[names(grouseShp) == 'x'] <- 'xProjected'
names(grouseShp)[names(grouseShp) == 'y'] <- 'yProjected'
# do it in lat lon
grouseShpLatLon <- spTransform(grouseShp, CRS(projLatLong))
grouseShpLatLon@data <- cbind(grouseShpLatLon@data,data.frame(gCentroid(grouseShpLatLon,byid=TRUE,id=NULL)@coords))
names(grouseShpLatLon)[names(grouseShpLatLon) == 'x'] <- 'xLatLon'
names(grouseShpLatLon)[names(grouseShpLatLon) == 'y'] <- 'yLatLon'
grouseShpLatLon <- spTransform(grouseShpLatLon, CRS("+proj=lcc +lat_1=45 +lat_2=49 +lat_0=44.25 +lon_0=-109.5 +x_0=600000 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"))
grouseShp <- grouseShpLatLon
# OUTPUT POLY WITH CENTROIDS ON ORIGINAL PROJECTION
# define x and y bounds so as to plot two things (original polygons and centroids) correctly
xmin <- grouseShp@bbox[1,1]
xmax <- grouseShp@bbox[1,2]
ymin <- grouseShp@bbox[2,1]
ymax <- grouseShp@bbox[2,2]
# output a simple plot
png(filename=paste0(grousePath,'/Results/GrouseCentroids.png',sep=""),width=9,height=6.5,units="in",res=300)
plot(grouseShp,xlim=c(xmin,xmax),ylim=c(ymin,ymax))
points(grouseShp@data$xProjected,grouseShp@data$yProjected,xlim=c(xmin,xmax),ylim=c(ymin,ymax),col='red',pch=19)
dev.off()
# OUTPUT POLY WITH CENTROIDS IN LAT LON
# define x and y bounds so as to plot two things (original polygons and centroids) correctly
# xmin <- grouseShpLatLon@bbox[1,1]
# xmax <- grouseShpLatLon@bbox[1,2]
# ymin <- grouseShpLatLon@bbox[2,1]
# ymax <- grouseShpLatLon@bbox[2,2]
#
# # output a simple plot
# png(filename=paste0(grousePath,'/Results/GrouseCentroidsLatLon.png',sep=""),width=9,height=6.5,units="in",res=300)
#   plot(grouseShpLatLon,xlim=c(xmin,xmax),ylim=c(ymin,ymax))
#   points(grouseShpLatLon@data$xLatLon,grouseShpLatLon@data$yLatLon,xlim=c(xmin,xmax),ylim=c(ymin,ymax),col='red',pch=19)
# dev.off()
# write out the updated shapefile in a new place
writeOGR(grouseShp,paste0(grousePath,'/Results'),'grouseCentroided',driver="ESRI Shapefile",overwrite_layer=TRUE)
# write out the data alone
write.csv(grouseShp,paste0(grousePath,'/Results/grouseCentroided.csv'))
require(rgdal)          # for reading and writing shapefiles
require(rgeos)          # for function gCentroid
# setup stuff
grousePath <- '\\\\LAR-FILE-SRV/Data/C. LeBeau/CentroidingGrouse'
grousePoly <- 'NHD_grouse_locs_fr_animal_soc'
projLatLong  <- "+init=epsg:4326"
# read in the data and add in the centroids
# do it in the projected system
grouseShp <- readOGR(paste0(grousePath,'/Data'),grousePoly);
grouseShp@data <- cbind(grouseShp@data,data.frame(gCentroid(grouseShp,byid=TRUE,id=NULL)@coords))
names(grouseShp)[names(grouseShp) == 'x'] <- 'xProjected'
names(grouseShp)[names(grouseShp) == 'y'] <- 'yProjected'
# do it in lat lon
grouseShpLatLon <- spTransform(grouseShp, CRS(projLatLong))
grouseShpLatLon@data <- cbind(grouseShpLatLon@data,data.frame(gCentroid(grouseShpLatLon,byid=TRUE,id=NULL)@coords))
names(grouseShpLatLon)[names(grouseShpLatLon) == 'x'] <- 'xLatLon'
names(grouseShpLatLon)[names(grouseShpLatLon) == 'y'] <- 'yLatLon'
grouseShpLatLon <- spTransform(grouseShpLatLon, CRS("+proj=lcc +lat_1=45 +lat_2=49 +lat_0=44.25 +lon_0=-109.5 +x_0=600000 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"))
grouseShp <- grouseShpLatLon
# OUTPUT POLY WITH CENTROIDS ON ORIGINAL PROJECTION
# define x and y bounds so as to plot two things (original polygons and centroids) correctly
xmin <- grouseShp@bbox[1,1]
xmax <- grouseShp@bbox[1,2]
ymin <- grouseShp@bbox[2,1]
ymax <- grouseShp@bbox[2,2]
# output a simple plot
png(filename=paste0(grousePath,'/Results/GrouseCentroids.png',sep=""),width=9,height=6.5,units="in",res=300)
plot(grouseShp,xlim=c(xmin,xmax),ylim=c(ymin,ymax))
points(grouseShp@data$xProjected,grouseShp@data$yProjected,xlim=c(xmin,xmax),ylim=c(ymin,ymax),col='red',pch=19)
dev.off()
# OUTPUT POLY WITH CENTROIDS IN LAT LON
# define x and y bounds so as to plot two things (original polygons and centroids) correctly
# xmin <- grouseShpLatLon@bbox[1,1]
# xmax <- grouseShpLatLon@bbox[1,2]
# ymin <- grouseShpLatLon@bbox[2,1]
# ymax <- grouseShpLatLon@bbox[2,2]
#
# # output a simple plot
# png(filename=paste0(grousePath,'/Results/GrouseCentroidsLatLon.png',sep=""),width=9,height=6.5,units="in",res=300)
#   plot(grouseShpLatLon,xlim=c(xmin,xmax),ylim=c(ymin,ymax))
#   points(grouseShpLatLon@data$xLatLon,grouseShpLatLon@data$yLatLon,xlim=c(xmin,xmax),ylim=c(ymin,ymax),col='red',pch=19)
# dev.off()
# write out the updated shapefile in a new place
writeOGR(grouseShp,paste0(grousePath,'/Results'),'grouseCentroided',driver="ESRI Shapefile",overwrite_layer=TRUE)
# write out the data alone
write.csv(grouseShp,paste0(grousePath,'/Results/grouseCentroided.csv'))
library(RODBC)
testing <- TRUE           # points to different output folders.
platform <- '20150501'    # points to different platforms
if(testing == FALSE){
paste(cat('testing == FALSE\n'))
source("\\LAR-FILE-SRV/Data/PSMFC_CampRST/ThePlatform/CAMP_RST20150204/R-Interface/source_all.R")
} else {
paste(cat('testing == TRUE\n'))
setwd(paste0("\\\\LAR-FILE-SRV/Data/PSMFC_CampRST/ThePlatform/CAMP_RST",platform,"/R-Interface/"))
source(paste0("\\\\LAR-FILE-SRV/Data/PSMFC_CampRST/ThePlatform/CAMP_RST",platform,"/R-Interface/source_all_testing.R"))
by <- 'week'
river <- 'Old American Test'
}
if(river == ''){
db.file <- db.file1
} else if(river == 'Sacramento River'){
db.file <- db.file2
} else if(river == 'American River'){
db.file <- db.file3
} else if(river == ''){
db.file <- db.file4
} else if(river == 'Feather River'){
db.file <- db.file5
} else if(river == 'Stanislaus River'){
db.file <- db.file6
} else if(river == 'Old American Test'){
db.file <- db.file7
}
if(river != 'Old American Test'){
site         <- theExcel[testi,]$siteID
siteText     <- theExcel[testi,]$Site
run          <- theExcel[testi,]$RunID
runText      <- theExcel[testi,]$SalmonRun
min.date     <- as.character(as.Date(theExcel[testi,]$minvisitTime,format = "%m/%d/%Y"))
max.date     <- as.character(as.Date(theExcel[testi,]$maxvisitTime,format = "%m/%d/%Y"))
} else {
river        <- 'american'
site         <- 57000
siteText     <- 'testing'
run          <- 3
runText      <- 'Fall'
min.date     <- "2013-10-01"
max.date     <- "2014-09-29"
#       min.date     <- "2012-10-01"
#       max.date     <- "2013-09-29"
}
taxon        <- 161980
if(testing == TRUE){
output.file  <- paste0("..//Outputs//",river,"//",river,"_",siteText,"_",min.date,"_",max.date)
} else {
output.file  <- paste0("..//Outputs//",river,"_",siteText,"_",min.date,"_",max.date)
}
ci           <- TRUE
output.type  <- "odt"
from         <- "Trent McDonald, Ph.D., WEST Incorporated"
to           <- "Doug Threloff, USFWS CAMP Coordinator"
return.addr  <- "FISH AND WILDLIFE SERVICE!USFWS Caswell State Park Office!1234 Abbey Rd.!Caswell, California  96080!(530) 527-3043, FAX (530) 529-0292"
>>>>>>> 9d98868ded31a228a275a2ef0e507154e8d0e2ca
#   ********
#   Check that times are less than 1 year apart
strt.dt <- as.POSIXct( min.date, format="%Y-%m-%d" )
end.dt <- as.POSIXct( max.date, format="%Y-%m-%d" )
run.season <- data.frame( start=strt.dt, end=end.dt )
dt.len <- difftime(end.dt, strt.dt, units="days")
if( dt.len > 366 )  stop("Cannot specify more than 365 days in F.passage. Check min.date and max.date.")
#   ---- Fetch efficiency data
release.df <- F.get.release.data( site, taxon, min.date, max.date  )
if( nrow(release.df) == 0 ){
stop( paste( "No efficiency trials between", min.date, "and", max.date, ". Check dates."))
}
#   ---- Fetch the catch and visit data
tmp.df   <- F.get.catch.data( site, taxon, min.date, max.date  )
catch.df <- tmp.df$catch   # All positive catches, all FinalRun and lifeStages, inflated for plus counts.  Zero catches (visits without catch) are NOT here.
visit.df <- tmp.df$visit   # the unique trap visits.  This will be used in a merge to get 0's later
<<<<<<< HEAD
catch.dfX <- catch.df      # save for a small step below.  several dfs get named catch.df, so need to call this something else.
#   Debugging
#    tmp.catch0 <<- catch.df
#    tmp.visit0 <<- visit.df
#    print( table(catch.df$TrapStatus))
if( nrow(catch.df) == 0 ){
stop( paste( "No catch records between", min.date, "and", max.date, ". Check dates and taxon."))
}
#   ---- Summarize catch data by trapVisitID X FinalRun X lifeStage. Upon return, catch.df has one line per combination of these variables
#catch.df <- F.summarize.fish.visit( catch.df )       jason turns off 4/15/2015
catch.df0 <- F.summarize.fish.visit( catch.df, 'unassigned' )   # jason - 5/20/2015 - we summarize over lifeStage, wrt to unassigned.
catch.df1 <- F.summarize.fish.visit( catch.df, 'inflated' )     # jason - 4/14/2015 - we summarize over lifeStage, w/o regard to unassigned.  this is what has always been done.
catch.df2 <- F.summarize.fish.visit( catch.df, 'assigned')      # jason - 4/14/2015 - we summarize over assigned.  this is new, and necessary to break out by MEASURED, instead of CAUGHT.
#                   - the only reason we do this again is to get a different n.tot.
#   Debugging
#    tmp.catch <<- catch.df
#    print( table(catch.df$TrapStatus))
#    cat("in lifestage_passage.r (hit return) ")
#    readline()
#   ---- Compute the unique runs we need to do
runs <- unique(c(catch.df1$FinalRun,catch.df2$FinalRun))    # get all instances over the two df.  jason change 4/17/2015 5/21/2015: don't think we need to worry about catch.df0.
runs <- runs[ !is.na(runs) ]
cat("\nRuns found between", min.date, "and", max.date, ":\n")
print(runs)
#   ---- Compute the unique life stages we need to do
lstages <- unique(c(catch.df1$lifeStage,catch.df2$lifeStage))   # get all instances over the two df.  jason change 4/17/2015 5/21/2015: don't think we need to worry about catch.df0.
lstages <- lstages[ !is.na(lstages) ]   #   Don't need this,  I am pretty sure lifeStage is never missing here.
cat("\nLife stages found between", min.date, "and", max.date, ":\n")
print(lstages)
#   ---- Print the number of non-fishing periods
cat( paste("\nNumber of non-fishing intervals at all traps:", sum(visit.df$TrapStatus == "Not fishing"), "\n\n"))
#   ---- Extract the unique trap visits.  This will be used in merge to get 0's later
#    ind <- !duplicated( catch.df$trapVisitID ) & !is.na(catch.df$trapVisitID)
#    visit.df <- catch.df[ind, ]
#    visit.df <- visit.df[, !(names(visit.df) %in% c("FinalRun", "lifeStage", "n.tot", "mean.fl", "sd.fl"))]
#   ********
#   Loop over runs
ans <- lci <- uci <- matrix(0, length(lstages), length(runs))
dimnames(ans)<-list(lstages, runs)
out.fn.roots <- NULL
j <- 1
run.name <<- runs[j]
# jason puts together the catches based on total, unassigned, assigned.
assd <- catch.df2[catch.df2$Unassd != 'Unassigned' & catch.df2$FinalRun == run.name,c('trapVisitID','lifeStage','n.tot','mean.fl','sd.fl')]
colnames(assd) <- c('trapVisitID','lifeStage','n.Orig','mean.fl.Orig','sd.fl.Orig')
catch.dfA <- merge(catch.df1,assd,by=c('trapVisitID','lifeStage'),all.x=TRUE)
unassd <- catch.df0[catch.df0$FinalRun == run.name,c('trapVisitID','lifeStage','n.tot')]
colnames(unassd) <- c('trapVisitID','lifeStage','n.Unassd')
# jason adds 6/7/2015 to throw out unassd counts from different runs that were creeping in.
catch.small <- catch.dfX[catch.dfX$Unassd == 'Unassigned' & catch.dfX$FinalRun == run.name,c('trapVisitID','lifeStage','Unmarked','Unassd')]
if(nrow(catch.small) > 0){
catch.small.tot <- aggregate(catch.small$Unmarked,list(trapVisitID=catch.small$trapVisitID,lifeStage=catch.small$lifeStage),sum)
names(catch.small.tot)[names(catch.small.tot) == 'x'] <- 'Unmarked'
preunassd <- merge(unassd,catch.small.tot,by=c('trapVisitID','lifeStage'),all.x=TRUE)
unassd <- preunassd[preunassd$n.Unassd == preunassd$Unmarked,]
unassd$Unmarked <-  NULL
}
catch.df <- merge(catch.dfA,unassd,by=c('trapVisitID','lifeStage'),all.x=TRUE)
catch.df <- catch.df[order(catch.df$trapPositionID,catch.df$batchDate),]
cat(paste(rep("*",80), collapse=""))
tmp.mess <- paste("Processing ", run.name)
cat(paste("\n", tmp.mess, "\n"))
cat(paste(rep("*",80), collapse=""))
cat("\n\n")
progbar <- winProgressBar( tmp.mess, label="Lifestage X run processing" )
barinc <- 1 / (length(lstages) * 6)
assign( "progbar", progbar, pos=.GlobalEnv )
indRun <- (catch.df$FinalRun == run.name ) & !is.na(catch.df$FinalRun)   # Don't need is.na clause.  FinalRun is never missing here.
i <- 1
ls <- lstages[i]
#   ---- Subset to just one life stage and run
indLS <- (catch.df$lifeStage == ls) & !is.na(catch.df$lifeStage) #  Don't need is.na clause.  I don't think lifeStage can be missing here.
cat(paste("Lifestage=", ls, "; Run=", run.name, "; num records=", sum(indRun & indLS), "\n"))
tmp.mess <- paste("Lifestage=", ls )
setWinProgressBar( progbar, getWinProgressBar(progbar)+barinc, label=tmp.mess )
#   ---- If we caught this run and lifestage, compute passage estimate.
any( indRun & indLS )
lstages
head(catch.df1)
head(catch.df2)
=======
>>>>>>> 9d98868ded31a228a275a2ef0e507154e8d0e2ca
#   ********
#   Check that times are less than 1 year apart
strt.dt <- as.POSIXct( min.date, format="%Y-%m-%d" )
end.dt <- as.POSIXct( max.date, format="%Y-%m-%d" )
run.season <- data.frame( start=strt.dt, end=end.dt )
dt.len <- difftime(end.dt, strt.dt, units="days")
if( dt.len > 366 )  stop("Cannot specify more than 365 days in F.passage. Check min.date and max.date.")
#   ---- Fetch efficiency data
release.df <- F.get.release.data( site, taxon, min.date, max.date  )
if( nrow(release.df) == 0 ){
stop( paste( "No efficiency trials between", min.date, "and", max.date, ". Check dates."))
}
<<<<<<< HEAD
#   ---- Fetch the catch and visit data
tmp.df   <- F.get.catch.data( site, taxon, min.date, max.date  )
catch.df <- tmp.df$catch   # All positive catches, all FinalRun and lifeStages, inflated for plus counts.  Zero catches (visits without catch) are NOT here.
visit.df <- tmp.df$visit   # the unique trap visits.  This will be used in a merge to get 0's later
catch.dfX <- catch.df      # save for a small step below.  several dfs get named catch.df, so need to call this something else.
#   Debugging
#    tmp.catch0 <<- catch.df
#    tmp.visit0 <<- visit.df
#    print( table(catch.df$TrapStatus))
if( nrow(catch.df) == 0 ){
stop( paste( "No catch records between", min.date, "and", max.date, ". Check dates and taxon."))
}
#   ---- Summarize catch data by trapVisitID X FinalRun X lifeStage. Upon return, catch.df has one line per combination of these variables
#catch.df <- F.summarize.fish.visit( catch.df )       jason turns off 4/15/2015
catch.df0 <- F.summarize.fish.visit( catch.df, 'unassigned' )   # jason - 5/20/2015 - we summarize over lifeStage, wrt to unassigned.
catch.df1 <- F.summarize.fish.visit( catch.df, 'inflated' )     # jason - 4/14/2015 - we summarize over lifeStage, w/o regard to unassigned.  this is what has always been done.
catch.df2 <- F.summarize.fish.visit( catch.df, 'assigned')      # jason - 4/14/2015 - we summarize over assigned.  this is new, and necessary to break out by MEASURED, instead of CAUGHT.
#                   - the only reason we do this again is to get a different n.tot.
#   Debugging
#    tmp.catch <<- catch.df
#    print( table(catch.df$TrapStatus))
#    cat("in lifestage_passage.r (hit return) ")
#    readline()
#   ---- Compute the unique runs we need to do
runs <- unique(c(catch.df1$FinalRun,catch.df2$FinalRun))    # get all instances over the two df.  jason change 4/17/2015 5/21/2015: don't think we need to worry about catch.df0.
runs <- runs[ !is.na(runs) ]
cat("\nRuns found between", min.date, "and", max.date, ":\n")
print(runs)
#   ---- Compute the unique life stages we need to do
lstages <- unique(c(catch.df1$lifeStage,catch.df2$lifeStage))   # get all instances over the two df.  jason change 4/17/2015 5/21/2015: don't think we need to worry about catch.df0.
lstages <- lstages[ !is.na(lstages) ]   #   Don't need this,  I am pretty sure lifeStage is never missing here.
cat("\nLife stages found between", min.date, "and", max.date, ":\n")
print(lstages)
#   ---- Print the number of non-fishing periods
cat( paste("\nNumber of non-fishing intervals at all traps:", sum(visit.df$TrapStatus == "Not fishing"), "\n\n"))
#   ---- Extract the unique trap visits.  This will be used in merge to get 0's later
#    ind <- !duplicated( catch.df$trapVisitID ) & !is.na(catch.df$trapVisitID)
#    visit.df <- catch.df[ind, ]
#    visit.df <- visit.df[, !(names(visit.df) %in% c("FinalRun", "lifeStage", "n.tot", "mean.fl", "sd.fl"))]
#   ********
#   Loop over runs
ans <- lci <- uci <- matrix(0, length(lstages), length(runs))
dimnames(ans)<-list(lstages, runs)
out.fn.roots <- NULL
j<-1
i<-1
run.name <<- runs[j]
# jason puts together the catches based on total, unassigned, assigned.
assd <- catch.df2[catch.df2$Unassd != 'Unassigned' & catch.df2$FinalRun == run.name,c('trapVisitID','lifeStage','n.tot','mean.fl','sd.fl')]
colnames(assd) <- c('trapVisitID','lifeStage','n.Orig','mean.fl.Orig','sd.fl.Orig')
catch.dfA <- merge(catch.df1,assd,by=c('trapVisitID','lifeStage'),all.x=TRUE)
unassd <- catch.df0[catch.df0$FinalRun == run.name,c('trapVisitID','lifeStage','n.tot')]
colnames(unassd) <- c('trapVisitID','lifeStage','n.Unassd')
# jason adds 6/7/2015 to throw out unassd counts from different runs that were creeping in.
catch.small <- catch.dfX[catch.dfX$Unassd == 'Unassigned' & catch.dfX$FinalRun == run.name,c('trapVisitID','lifeStage','Unmarked','Unassd')]
if(nrow(catch.small) > 0){
catch.small.tot <- aggregate(catch.small$Unmarked,list(trapVisitID=catch.small$trapVisitID,lifeStage=catch.small$lifeStage),sum)
names(catch.small.tot)[names(catch.small.tot) == 'x'] <- 'Unmarked'
preunassd <- merge(unassd,catch.small.tot,by=c('trapVisitID','lifeStage'),all.x=TRUE)
unassd <- preunassd[preunassd$n.Unassd == preunassd$Unmarked,]
unassd$Unmarked <-  NULL
}
catch.df <- merge(catch.dfA,unassd,by=c('trapVisitID','lifeStage'),all.x=TRUE)
catch.df <- catch.df[order(catch.df$trapPositionID,catch.df$batchDate),]
cat(paste(rep("*",80), collapse=""))
tmp.mess <- paste("Processing ", run.name)
cat(paste("\n", tmp.mess, "\n"))
cat(paste(rep("*",80), collapse=""))
cat("\n\n")
progbar <- winProgressBar( tmp.mess, label="Lifestage X run processing" )
barinc <- 1 / (length(lstages) * 6)
assign( "progbar", progbar, pos=.GlobalEnv )
indRun <- (catch.df$FinalRun == run.name ) & !is.na(catch.df$FinalRun)   # Don't need is.na clause.  FinalRun is never missing here.
ls <- lstages[i]
#   ---- Subset to just one life stage and run
indLS <- (catch.df$lifeStage == ls) & !is.na(catch.df$lifeStage) #  Don't need is.na clause.  I don't think lifeStage can be missing here.
cat(paste("Lifestage=", ls, "; Run=", run.name, "; num records=", sum(indRun & indLS), "\n"))
tmp.mess <- paste("Lifestage=", ls )
setWinProgressBar( progbar, getWinProgressBar(progbar)+barinc, label=tmp.mess )
catch.df.ls <- catch.df[ indRun & indLS, c("trapVisitID", "FinalRun", "lifeStage", 'n.Orig','mean.fl.Orig','sd.fl.Orig',"n.tot", "mean.fl", "sd.fl","n.Unassd")]
#   ---- Merge in the visits to get zeros
catch.df.ls <- merge( visit.df, catch.df.ls, by="trapVisitID", all.x=T )
setWinProgressBar( progbar, getWinProgressBar(progbar)+barinc )
#   ---- Update the constant variables.  Missing n.tot when trap was fishing should be 0.
catch.df.ls$FinalRun[ is.na(catch.df.ls$FinalRun) ] <- run.name
catch.df.ls$lifeStage[ is.na(catch.df.ls$lifeStage) ] <- ls
catch.df.ls$n.tot[ is.na(catch.df.ls$n.tot) & (catch.df.ls$TrapStatus == "Fishing") ] <- 0
catch.df.ls$n.Orig[ is.na(catch.df.ls$n.Orig) & (catch.df.ls$TrapStatus == "Fishing") ] <- 0
catch.df.ls$n.Unassd[ is.na(catch.df.ls$n.Unassd) & (catch.df.ls$TrapStatus == "Fishing") ] <- 0
#   ---- Add back in the missing trapVisitID rows.  These identify the gaps in fishing
#catch.df.ls <- rbind( catch.df.ls, catch.df[ is.na(catch.df$trapVisitID), ] )
#   ---- Update progress bar
out.fn.root <- paste0(output.file, ls, run.name )
setWinProgressBar( progbar, getWinProgressBar(progbar)+barinc )
#   Debugging
#                tmp.c <<- catch.df.ls
#                tmp.r <<- release.df
#   Debugging
#                print(dim(visit.df))
#                print(dim(catch.df.ls))
#                print( table( tmp.c$FinalRun, useNA="always" ))
#                print( table( tmp.c$lifeStage, useNA="always" ))
#                print( table( tmp.c$trapVisitID, useNA="always" ))
#                cat("in lifestage_passage (hit return) ")
#                readline()
#   ---- Compute passage
catch.df <- catch.df.ls
release.df <- release.df
summarize.by <- by
file.root <- out.fn.root
ci <- ci
#
#   Output,
#   A data frame containing date, passage estimate, and SE of passage estimate.
#
catch.df.sites <- unique(catch.df[,c('trapPositionID','TrapPosition')])                     # jason add
colnames(catch.df.sites) <- c('subSiteID','subSiteName')                                    # jason add
#catch.df$n.Orig <- ifelse(is.na(catch.df$n.Orig) & catch.df$TrapStatus == 'Fishing',0,catch.df$n.Orig)   # jason add -- 4/15/2015 delete 5/20/2015.  do with other 0 overwrite in passage.R
time.zone <- get("time.zone", env=.GlobalEnv )
f.banner <- function( x ){
cat("\n")
cat(paste(rep("=",50), collapse=""));
cat(x);
cat(paste(rep("=",50), collapse=""));
cat("\n")
}
f.banner(" F.est.passage - START ")
#   This keeps track of the files produced
out.fn.list <- NULL
#   retrieve the progress bar
usepb <- exists( "progbar", where=.GlobalEnv )
# jason add: this data frame has the raw unmarked counts of catch.  note that rows with missing data for certain days, i.e., for which imputation
# occurs also appear as line items here.  so, to get catch, for different trapPositionID/subSiteID, summarise and add togeter (b/c some
# days have more than one record).  brings back more dates than ultimately wanted; let merge below (after grand.df) take care of which
# to keep.
jason.catch2.df <- catch.df[,c('trapVisitID','batchDate','trapPositionID','n.Orig')]
jason.catch3.df <- data.frame(with(jason.catch2.df,tapply(n.Orig, list(batchDate,trapPositionID), sum, na.rm=T )))
jason.catch4.df <- na.omit(reshape(jason.catch3.df,idvar='batchDate',ids=row.names(jason.catch3.df),times=names(jason.catch3.df),timevar='trapPositionID',varying=list(names(jason.catch3.df)),direction='long'))
colnames(jason.catch4.df)[2] <- 'rawCatch'
jason.catch4.df$trapPositionID <- as.character(substr(jason.catch4.df$trapPositionID,2,nchar(jason.catch4.df$trapPositionID)))
jason.catch4.df$batchDate <- as.POSIXct(jason.catch4.df$batchDate,time.zone)
# jason 4/15/2015, do the same thing as above, but with n.tot.  sloppy to do this twice like this, but i know the above works.
jason.totCatch2.df <- catch.df[,c('trapVisitID','batchDate','trapPositionID','n.tot')]
jason.totCatch3.df <- data.frame(with(jason.totCatch2.df,tapply(n.tot, list(batchDate,trapPositionID), sum, na.rm=T )))
jason.totCatch4.df <- na.omit(reshape(jason.totCatch3.df,idvar='batchDate',ids=row.names(jason.totCatch3.df),times=names(jason.totCatch3.df),timevar='trapPositionID',varying=list(names(jason.totCatch3.df)),direction='long'))
colnames(jason.totCatch4.df)[2] <- 'inflatedCatch'
jason.totCatch4.df$trapPositionID <- as.character(substr(jason.totCatch4.df$trapPositionID,2,nchar(jason.totCatch4.df$trapPositionID)))
jason.totCatch4.df$batchDate <- as.POSIXct(jason.totCatch4.df$batchDate,time.zone)
#   ------------------------------------------------------------------
#   Estimate capture for every day of season.  Return value is
#   data frame with columns $batchDate and $catch.
#   By default, this produces one graph in a pdf.  Turn this off with plot=F in call.
#       catch.and.fits has components $catch, $fits, $X.miss, $gaps, $bDates.miss, and $trapsOperating
plot.file=file.root
time.zone <- get("time.zone", env=.GlobalEnv )
#   ---- Establish the days on which estimates need to be produced.
#        Times in run season must be same as time in batchDate each day.
#        batchDate must occur at same time every day.  Can be missing days, but always at same time when present.
#start.season <- min(catch.df$batchDate)
#end.season   <- max(catch.df$batchDate)
#   ---- Fill in the gaps for individual traps
df <- NULL
true.imp <- NULL
u.traps <- unique( catch.df$trapPositionID )
catch.fits <- X.miss <- Gaps <- bDates.miss <- vector("list", length(u.traps))   # lists to contain thing to save for bootstrapping
names(catch.fits) <- u.traps
# catch.dff <<- catch.df   # save a copy for debugging
u.traps
trap in u.traps
trap <- 4001
df2 <- catch.df[catch.df$trapPositionID == trap,]
#   Impute a value for the gaps
#   When df2 comes back from F.catch.model, it has extra lines in it.  One extra line for each 24 hour period in the
#   gaps that were bigger than max.ok.gap. If gap = 3 days, there will be 3 extra lines.
#   sampleStart and sampleEnd for each of the new lines are defined so that no gap appears  now.  Variable
#   'gamEstimated' is true for these periods. Batch date is assigned based on sampleEnd, as usual.
#   On return, there is a value or imputed value for each day from start of season to end of season.
catch.df <- df2
#   Sort the data frame properly, by trapPosition and date of visit
#   This puts the gaps in their correct locations
catch.df <- catch.df[ order(catch.df$trapPositionID, catch.df$EndTime), ]
#   Compute the "night" variables.
time.zone <- get("time.zone", env=.GlobalEnv )
sunset  <- as.POSIXct( paste(format(catch.df$StartTime, "%Y-%m-%d"), "19:00:00"), format="%Y-%m-%d %H:%M:%S", tzone=time.zone )
sunrise <- as.POSIXct( paste(format(catch.df$EndTime, "%Y-%m-%d"), "07:00:00"), format="%Y-%m-%d %H:%M:%S", tzone=time.zone )
catch.df$night <- 0
catch.df$pct.night <- 0
ind <- (catch.df$StartTime <= sunset) & (sunrise <= catch.df$EndTime)
catch.df$night[ind] <- 1
catch.df$pct.night[ind] <- 1
ind <- (catch.df$StartTime <= sunset) & (sunrise > catch.df$EndTime)
catch.df$night[ind] <- 1
catch.df$pct.night[ind] <- (as.numeric(catch.df$EndTime[ind]) - as.numeric(sunset[ind])) / (as.numeric(sunrise[ind]) - as.numeric(sunset[ind]))
ind <- (catch.df$sampleStart > sunset) & (sunrise <= catch.df$EndTime)
catch.df$night[ind] <- 1
catch.df$pct.night[ind] <- (as.numeric(sunrise[ind]) - as.numeric(catch.df$StartTime[ind])) / (as.numeric(sunrise[ind]) - as.numeric(sunset[ind]))
#   Fit a rate model.
library(splines)
#catch.df <- catch.df[ catch.df$TrapStatus == "Fishing", ]
catch.df$log.sampleLengthHrs <- log(as.numeric( catch.df$SampleMinutes/60 ))
p.night <- sum(catch.df$night) / nrow(catch.df)
#   Fit null model.  The gap catches are NA here, so they are dropped from the fit.  Later, they are replaced.
if( p.night < 0.9 ){
fit <- glm( n.tot ~ offset(log.sampleLengthHrs)  + night, family=poisson, data=catch.df )
} else {
fit <- glm( n.tot ~ offset(log.sampleLengthHrs) , family=poisson, data=catch.df )
}
fit.AIC <- AIC(fit)
p.night
glm( n.tot ~ offset(log.sampleLengthHrs)  + night, family=poisson, data=catch.df )
n.tot
catch.df
glm( n.tot ~ offset(log.sampleLengthHrs) , family=poisson, data=catch.df[rownames(catch.df) != 66,] )
=======
#   *****
nvisits <- F.buildReportCriteria( site, min.date, max.date )
if( nvisits == 0 ){
warning("Your criteria returned no trapVisit table records.")
return()
}
#   *****
#   Open ODBC channel
db <- get( "db.file", env=.GlobalEnv )
ch <- odbcConnectAccess(db)
#   *****
#   This SQL file develops the hours fished and TempSamplingSummary table
F.run.sqlFile( ch, "QrySamplePeriod.sql", R.TAXON=taxon )
#   *****
#   This SQL generates times when the traps were not fishing
F.run.sqlFile( ch, "QryNotFishing.sql" )
#   *****
#   This SQL generates unmarked fish by run and life stage
F.run.sqlFile( ch, "QryUnmarkedByRunLifestage.sql", R.TAXON=taxon )
#   *****
#   Now, fetch the result
catch <- sqlFetch( ch, "TempSumUnmarkedByTrap_Run_Final" )
F.sql.error.check(catch)
close(ch)
#   ******************************************************************
#   Assign time zone (probably does not matter)
time.zone <- get( "time.zone", env=.GlobalEnv )
attr(catch$StartTime, "tzone") <- time.zone
attr(catch$EndTime, "tzone") <- time.zone
#   ********************************************************************
#   At this point, catch has all visits in it, even if no fish were caught.
#   It also has non-fishing intervals.  This is how you identify these intervals:
#       1. zero catch = catch$Unmarked == 0  ($FinalRun and $LifeStage are both "Unassigned" for these lines)
#       2. not fishing = catch$TrapStatus == "Not fishing"  (equivalently, $trapVisitID is missing for these lines.  Only time its missing.)
#
#   Pull apart the visits from the catch, because plus count expansion only applys to positive catches.
#   Recall, catch currently has multiple lines per trapVisit delineating fish with different fork lengths.
visit.ind <- !duplicated( catch$trapVisitID ) | (catch$TrapStatus == "Not fishing")
visits <- catch[visit.ind,!(names(catch) %in% c("Unmarked", "FinalRun", "lifeStage", "forkLength", "RandomSelection"))]
#   ********************************************************************
#   Subset the catches to just positives.  Toss the 0 catches and non-fishing visits.
catch <- catch[ (catch$Unmarked > 0) & (catch$TrapStatus == "Fishing"), ]
catch$Unassd <- catch$lifeStage # jason add to ID the unassigned lifeStage -- necessary to separate measured vs caught.
#   ********************************************************************
#   Expand the Plus counts
catch <- F.expand.plus.counts( catch )
#   Reassign factor levels because they may have changed.  I.e., we may have eliminated "Unassigned"
catch$FinalRun <- as.character( catch$FinalRun )
catch$lifeStage <- as.character( catch$lifeStage )
#catch$lifeStage <- as.character( catch$Unassd ) jason - possibly delete
df <- catch
>>>>>>> 9d98868ded31a228a275a2ef0e507154e8d0e2ca
