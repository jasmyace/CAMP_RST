cat(paste(rep("=",50), collapse=""));
cat("\n")
}
f.banner(" F.est.passage - START ")
#   This keeps track of the files produced
out.fn.list <- NULL
#   retrieve the progress bar
usepb <- exists( "progbar", where=.GlobalEnv )
# jason add: this data frame has the raw unmarked counts of catch.  note that rows with missing data for certain days, i.e., for which imputation
# occurs also appear as line items here.  so, to get catch, for different trapPositionID/subSiteID, summarise and add togeter (b/c some
# days have more than one record).  brings back more dates than ultimately wanted; let merge below (after grand.df) take care of which
# to keep.
jason.catch2.df <- catch.df[,c('trapVisitID','batchDate','trapPositionID','n.Orig')]
jason.catch3.df <- data.frame(with(jason.catch2.df,tapply(n.Orig, list(batchDate,trapPositionID), sum, na.rm=T )))
jason.catch4.df <- na.omit(reshape(jason.catch3.df,idvar='batchDate',ids=row.names(jason.catch3.df),times=names(jason.catch3.df),timevar='trapPositionID',varying=list(names(jason.catch3.df)),direction='long'))
colnames(jason.catch4.df)[2] <- 'rawCatch'
jason.catch4.df$trapPositionID <- as.character(substr(jason.catch4.df$trapPositionID,2,nchar(jason.catch4.df$trapPositionID)))
jason.catch4.df$batchDate <- as.POSIXct(jason.catch4.df$batchDate,time.zone)
# jason 4/15/2015, do the same thing as above, but with n.tot.  sloppy to do this twice like this, but i know the above works.
jason.totCatch2.df <- catch.df[,c('trapVisitID','batchDate','trapPositionID','n.tot')]
jason.totCatch3.df <- data.frame(with(jason.totCatch2.df,tapply(n.tot, list(batchDate,trapPositionID), sum, na.rm=T )))
jason.totCatch4.df <- na.omit(reshape(jason.totCatch3.df,idvar='batchDate',ids=row.names(jason.totCatch3.df),times=names(jason.totCatch3.df),timevar='trapPositionID',varying=list(names(jason.totCatch3.df)),direction='long'))
colnames(jason.totCatch4.df)[2] <- 'inflatedCatch'
jason.totCatch4.df$trapPositionID <- as.character(substr(jason.totCatch4.df$trapPositionID,2,nchar(jason.totCatch4.df$trapPositionID)))
jason.totCatch4.df$batchDate <- as.POSIXct(jason.totCatch4.df$batchDate,time.zone)
#   ------------------------------------------------------------------
#   Estimate capture for every day of season.  Return value is
#   data frame with columns $batchDate and $catch.
#   By default, this produces one graph in a pdf.  Turn this off with plot=F in call.
#       catch.and.fits has components $catch, $fits, $X.miss, $gaps, $bDates.miss, and $trapsOperating
catch.and.fits <- F.est.catch( catch.df, plot=TRUE, plot.file=file.root )
if(usepb){
progbar <- get( "progbar", pos=.GlobalEnv )
tmp <- getWinProgressBar(progbar)
setWinProgressBar(progbar, (2*tmp + 1)/3 )
}
catch <- catch.and.fits$catch
# the catch dataframe in this list has the imputed values already overwriting the original numbers
jason.catch.and.fits2.df <- catch.and.fits$true.imp
jason.catch.and.fits3.df <- data.frame(with(jason.catch.and.fits2.df,tapply(n.tot, list(batchDate,trapPositionID), sum, na.rm=T )))
jason.catch.and.fits4.df <- na.omit(reshape(jason.catch.and.fits3.df,idvar='batchDate',ids=row.names(jason.catch.and.fits3.df),times=names(jason.catch.and.fits3.df),timevar='trapPositionID',varying=list(names(jason.catch.and.fits3.df)),direction='long'))
colnames(jason.catch.and.fits4.df)[2] <- 'ImputedCatch'
jason.catch.and.fits4.df$trapPositionID <- as.character(substr(jason.catch.and.fits4.df$trapPositionID,2,nchar(jason.catch.and.fits4.df$trapPositionID)))
jason.catch.and.fits4.df$batchDate <- as.POSIXct(jason.catch.and.fits4.df$batchDate,time.zone)
out.fn.list <- c(out.fn.list, attr(catch.and.fits, "out.fn.list"))
#catch.fits <- catch.and.fits$fits  # fits are needed for variance computation
#print(catch[1:20,])
#   ------------------------------------------------------------------
#   Estimate trap efficiency for every batchDate of season.  Return value is
#   data frame with columns $batchDate and $eff.
#   If plot=T, this produces a graph in a pdf.
f.banner(" Efficiency estimation ")
bd <- sort( unique(catch$batchDate) )
eff.and.fits <- F.est.efficiency( release.df, bd, method=3, df=3, plot=TRUE, plot.file=file.root )
if(usepb){
tmp <- getWinProgressBar(progbar)
setWinProgressBar(progbar, (2*tmp + 1)/3 )
}
efficiency <- eff.and.fits$eff
out.fn.list <- c(out.fn.list, attr(eff.and.fits, "out.fn.list"))
if( all(is.na(efficiency[1,])) ){
#   Something is wrong with efficiency data. Make an empty efficiency data frame
efficiency <- data.frame( trapPositionID=catch$trapPositionID, batchDate=catch$batchDate, efficiency=rep(NA, nrow(catch)))
warning("Zero efficiency")
}
#   could do this n <- data.base( catch, efficiency=efficiency$efficiency, gam.estimated.eff=efficiency$gam.estimated )
#   to produce a data frame of values that go into estimator, one line per batchDate
#   ------------------------------------------------------------------
#   Now, estimate passage
if( any(ind <- !is.na(efficiency$efficiency) & (efficiency$efficiency <= 0)) ){    # shouldn't happen that efficiency <= 0, but just in case.  This also gives us a way to exclude days (just set efficiency <= 0)
efficiency$efficiency[ind] <- NA
}
#   First merge catch and efficiency data frames
catch$batchDay <- format(catch$batchDate, "%Y-%m-%d")
catch$trapPositionID <- as.character(catch$trapPositionID)
efficiency$batchDay <- format(efficiency$batchDate, "%Y-%m-%d")
efficiency$trapPositionID <- as.character(efficiency$trapPositionID)
efficiency <- efficiency[,names(efficiency) != "batchDate"]  # drop POSIX date from efficiency
cat("First 20 rows of CATCH...\n")
print(catch[1:20,])
cat("First 20 rows of EFFICIENCY...\n")
print(efficiency[1:20,])
##   Add a trapFunctioning column so can tell when traps start and stop.
#print(catch[1:10,])
#print(catch.and.fits$trapsOperating[1:10,])
#
#catch <- merge( catch, catch.and.fits$trapsOperating, by=c("trapPositionID","batchDate") )
#
#tmp.catch <<- catch
#   The Grand Merge.  Merge catch info with efficiency info.
grand.df <- merge( catch, efficiency, by=c("trapPositionID", "batchDay"), all=T)
#   For each trap, drop the dates that are outside it's start and stop date.  This
#   The season for each trap is identified as non missing catch.  I.e., the grand merge puts
#   in every date because efficiency data frame has all dates.
grand.df <- grand.df[!is.na(grand.df$catch), ]
grand.df.rawCatch <- merge(grand.df,jason.catch4.df,by=c('trapPositionID','batchDate'),all.x=TRUE)                                   # bring in raw catch (measured)
grand.df.rawCatch.Inflated <- merge(grand.df.rawCatch,jason.totCatch4.df,by=c('trapPositionID','batchDate'),all.x=TRUE)                 # bring in inflated catch (measured + plus counts)
grand.df.rawCatch.Imputed <- merge(grand.df.rawCatch.Inflated ,jason.catch.and.fits4.df,by=c('trapPositionID','batchDate'),all.x=TRUE)  # bring in imputed catch
grand.df <- grand.df.rawCatch.Imputed
# somewhere, there are comments that state that catches of NA mean zero.  so, replace NA in each of
# rawCatch and ImputedCatch with zero.
grand.df$assignedCatch <- ifelse(is.na(grand.df$rawCatch), 0, grand.df$rawCatch)
grand.df$inflatedCatch <- ifelse(is.na(grand.df$inflatedCatch), 0, grand.df$inflatedCatch)
grand.df$unassignedCatch <- ifelse(is.na(grand.df$UnassdCatch), 0, grand.df$UnassdCatch)
grand.df$imputedCatch <- ifelse(is.na(grand.df$ImputedCatch), 0, round(grand.df$ImputedCatch,1))
grand.df$totalCatch <- ifelse(is.na(grand.df$inflatedCatch + grand.df$imputedCatch), 0, round(grand.df$inflatedCatch + grand.df$imputedCatch,1))
grand.df$rawCatch <- grand.df$ImputedCatch <- grand.df$catch <- grand.df$UnassdCatch <- NULL
# check and make sure that assignedCatch + unassignedCatch + imputedCatch = totalCatch
# check and make sure that assignedCatch + unassignedCatch = inflatedCatch
# check and make sure that inflatedCatch + imputedCatch = totalCatch
grand.df$sum1 <- grand.df$assignedCatch + grand.df$unassignedCatch + grand.df$imputedCatch
grand.df$sum2 <- grand.df$assignedCatch + grand.df$unassignedCatch
grand.df$sum3 <- grand.df$inflatedCatch + grand.df$imputedCatch
grand.df$check1 <- ifelse(grand.df$sum1 == grand.df$totalCatch,TRUE,FALSE)
grand.df$check2 <- ifelse(grand.df$sum2 == grand.df$inflatedCatch,TRUE,FALSE)
grand.df$check3 <- ifelse(grand.df$sum3 == grand.df$totalCatch,TRUE,FALSE)
if(sum(grand.df$check1 + grand.df$check2 + grand.df$check3) != nrow(grand.df)*3){
stop('Issue with summation of assignedCatch, unassignedCatch, inflatedCatch, imputedCatch, and/or totalCatch.  Investigate est_passage.R, around line 176.')
} else {
cat('No issue with summation of assignedCatch, unassignedCatch, inflatedCatch, imputedCatch, and/or totalCatch.  Continuing...\n')
}
#   The passage estimator
grand.df$passage <- rep(NA, nrow(grand.df))
grand.df$passage <- grand.df$totalCatch / grand.df$efficiency
grand.df$passage <- round(grand.df$passage,1)   # round final passage estimate here so different summaries sum to the same number.
#   Save grand.df to .GlobalEnv (for debuggin) and write it out to a csv file
# catch.df <<- catch
# grand.df <<- grand.df
cat("grand.df stored in .GlobalEnv\n")
if( !is.na(file.root) ){
tmp.df <- grand.df[, !(names(grand.df) %in% c("nReleased", "nCaught", "batchDay")) ]  # do this so can change names (headers) in csv file, Drop 2 columns
names(tmp.df)[ names(tmp.df) == "imputed.catch" ] <- "propImputedCatch"
names(tmp.df)[ names(tmp.df) == "imputed.eff" ] <- "propImputedEff"
tmp.df$propImputedEff <- as.numeric(tmp.df$propImputedEff)  # convert to numbers, 0 or 1
tmp.df$passage <- round(tmp.df$passage)  # Round off passage
tmp.df$totalCatch <- round(tmp.df$totalCatch,1)
tmp.df$efficiency <- round(tmp.df$efficiency, 4)
# Merge in subsiteNames
# ssiteNames <- attr(catch, "subsites")    # jason turn off
ssiteNames <- catch.df.sites               # jason turn on
tmp.df <- merge( ssiteNames, tmp.df, by.x="subSiteID", by.y="trapPositionID", all.y=T )
out.fn <- paste(file.root, "_baseTable.csv", sep="")
tmp.df$TrapPosition <- tmp.df$TrapPositionID <- NULL
#tmp.df$includeCatchID <- ifelse(is.na(tmp.df$includeCatchID),NA,ifelse(tmp.df$includeCatchID == 1,'Yes',ifelse(tmp.df$includeCatchID == 12,'Yes+No','No')))
tmp.df <- tmp.df[c('subSiteID','subSiteName','batchDate','assignedCatch','unassignedCatch','imputedCatch','totalCatch','propImputedCatch','efficiency','propImputedEff','passage')]    # rearrange columns
write.table( tmp.df, file=out.fn, sep=",", row.names=FALSE, col.names=TRUE)
out.fn.list <- c(out.fn.list, out.fn)
}
# ====== Passage estimates are done by day.  Compute variance and summarize ====================================================================================================
f.banner(paste(" Bootstrapping, if called for, and summarizing by", summarize.by))
n <- F.bootstrap.passage( grand.df, catch.and.fits$fits, catch.and.fits$X.miss, catch.and.fits$gaps,
catch.and.fits$bDates.miss, eff.and.fits$fits, eff.and.fits$X, eff.and.fits$ind.inside,
eff.and.fits$X.dates, summarize.by, 100, ci )
if(usepb){
tmp <- getWinProgressBar(progbar)
setWinProgressBar(progbar, tmp + (1-tmp)*.9 )
}
index.aux <- F.summarize.index( catch.df$batchDate, summarize.by )
# jason: for some reason, for testi = 7, bootstrap passage brings back one year, but summarize index brings back
# another, when calculating per year.  this messes up the join below. force the two to be the
# same in this one case.
if(summarize.by == 'year'){
n[1,1] <- index.aux[[1]][1]
}
#   Mean Forklength
num <- catch.df$mean.fl.Orig * catch.df$n.Orig
num <- tapply( num, index.aux, sum, na.rm=T )
#   SD of Forklength
num.sd <- (catch.df$sd.fl.Orig * catch.df$sd.fl.Orig) * (catch.df$n.Orig  - 1)    # this is sum of squares -- well, without the summing just yet
num.sd <- tapply( num.sd, index.aux, sum, na.rm=T )
#   n
den <- tapply( catch.df$n.Orig, index.aux, sum, na.rm=T)
#   Mean and SD computations
aux.fl <- ifelse( den > 0, num / den, NA )
aux.sd <- ifelse( den > 1, sqrt(num.sd / (den-1)), NA )
catch.df.reduced <- aggregate(catch.df,by=list(ID=catch.df$batchDate),head,1)  # 6/5/2015 - jason reduces df to select first of each and changes to batchdate...
catch.df.Fishing <- catch.df
catch.df.Fishing$SampleMinutes <- ifelse(catch.df.Fishing$TrapStatus == 'Not fishing',0,catch.df.Fishing$SampleMinutes)
catch.df.Fishing <- unique(catch.df.Fishing[,c('SampleMinutes','batchDate','trapPositionID')])
num <-  aggregate(catch.df.Fishing$SampleMinutes,by=list(ID=catch.df.Fishing$batchDate),sum)[,2]
#   Amount of time sampled
# if(summarize.by == "day"){
#   catch.df.reduced <- aggregate(catch.df,by=list(ID=catch.df$batchDate),head,1)  # 6/5/2015 - jason reduces df to select first of each and changes to batchdate...
#   catch.df.Fishing <- catch.df
#   catch.df.Fishing$SampleMinutes <- ifelse(catch.df.Fishing$TrapStatus == 'Not fishing',0,catch.df.Fishing$SampleMinutes)
#   catch.df.Fishing <- unique(catch.df.Fishing[,c('SampleMinutes','batchDate','trapPositionID')])
#   num <-  aggregate(catch.df.Fishing$SampleMinutes,by=list(ID=catch.df.Fishing$batchDate),sum)[,2]
# } else {
#   catch.df.reduced <- aggregate(catch.df,by=list(ID=catch.df$trapVisitID),head,1)  # 4/13/2015 - jason reduces df to select first of each
#   num <- as.numeric( catch.df.reduced$SampleMinutes )                                   # 4/13/2015 - jason pulls from reduced df
# }
tzn <- get("time.zone", .GlobalEnv )                                                   # batchDate defaults to mountain time. fix that.
catch.df.reduced$batchDate <- as.POSIXct( strptime( format(catch.df.reduced$batchDate, "%Y-%m-%d"), "%Y-%m-%d", tz=tzn),tz=tzn)   # fix the time.
index.aux <- F.summarize.index(catch.df.reduced$batchDate,summarize.by)               # 4/13/2015 - jason indexes in reduced df
aux.hrs <- tapply( num, index.aux, sum, na.rm=T )/60                                  # this is hours actually sampled during the 'index' period
#den <- rep( 24, length(batchDate.filled) )
#den <- tapply( den, index.aux2, sum, na.rm=T )  # this is total hours in 'index' period
#
#   Note: I will leave the commented out code that computes amount of time in each index period.  The reason
#   I commented it out is that 'den' may have more rows than num.  i.e., catch.df$batchDate may have fewer rows than batchDate.filled.
#   This makes 'den' difficult to merge back in to 'num', but it could be done.
aux<-data.frame( s.by=dimnames(aux.fl)[[1]],
nForkLenMM=c(den),
meanForkLenMM=c(aux.fl),
sdForkLenMM=c(aux.sd),
sampleLengthHrs=c(aux.hrs),
stringsAsFactors=F, row.names=NULL )
#   ---- Merge 'n' and 'aux' information together
n <- merge(n,aux, by="s.by", all.x=T)
n$sampleLengthDays <- n$sampleLengthHrs / 24
tz.offset <- as.numeric(as.POSIXct(0, origin="1970-01-01", tz=time.zone))
n$date <- as.POSIXct( n$date-tz.offset, origin="1970-01-01", tz=time.zone )  # I think this only works west of GMT (North America).  East of GMT, it may be 12 hours off. UNTESTED east of GMT
#   Put the final data frame together
names(n)[names(n) == "s.by"] <- summarize.by
attr(n, "taxonID" ) <- attr(catch.df,"taxonID")
attr(n, "species.name") <- attr(catch.df, "species.name")
attr(n, "siteID" ) <- attr(catch.df,"siteID")
attr(n, "site.name") <- attr(catch.df, "site.name")
attr(n, "site.abbr") <- attr(catch.df, "site.abbr")
attr(n, "runID") <- attr(catch.df, "runID")
attr(n, "run.name") <- attr(catch.df, "run.name")
attr(n, "year") <- attr(catch.df, "year")
attr(n, "run.season") <- attr(catch.df, "run.season")
attr(n, "summarized.by") <- summarize.by
attr(n, "out.fn.list") <- out.fn.list
attr(n, "trapsOperating") <- catch.and.fits$trapsOperating
f.banner(" F.est.passage - COMPLETE ")
output.file  <- paste0("..//Outputs//",river,"_",siteText,"_",min.date,"_",max.date)
output.file
F.run.passage     ( site, taxon,      min.date, max.date, by=by,        output.file=output.file,                     ci=TRUE            )
close(db)
close(ch)
ch
close(ch)
stop
odbcClose(ch)
ch
close(ch)
close(ch)
close(ch)
river        <- ''
site         <- 21000
siteText     <- 'testing'
run          <- 3
runText      <- 'Fall'
min.date     <- "2013-11-01"
max.date     <- "2014-06-01"
paste(cat('testing == FALSE\n'))
source("\\LAR-FILE-SRV/Data/PSMFC_CampRST/ThePlatform/CAMP_RST20150204/R-Interface/source_all.R")
paste(cat('testing == FALSE\n'))
source("\\LAR-FILE-SRV/Data/PSMFC_CampRST/ThePlatform/CAMP_RST20151123/R-Interface/source_all.R")
paste(cat('testing == TRUE\n'))
setwd(paste0("\\\\LAR-FILE-SRV/Data/PSMFC_CampRST/ThePlatform/",platform,"/R-Interface/"))
source(paste0("\\\\LAR-FILE-SRV/Data/PSMFC_CampRST/ThePlatform/",platform,"/R-Interface/source_all_testing.R"))
testing <- TRUE           # points to different output folders.
platform <- 'CAMP_RST20151123'    # points to different platforms
paste(cat('testing == TRUE\n'))
setwd(paste0("\\\\LAR-FILE-SRV/Data/PSMFC_CampRST/ThePlatform/",platform,"/R-Interface/"))
source(paste0("\\\\LAR-FILE-SRV/Data/PSMFC_CampRST/ThePlatform/",platform,"/R-Interface/source_all_testing.R"))
db.file <- db.file1
source("\\\\LAR-FILE-SRV/Data/PSMFC_CampRST/ThePlatform/CAMP_RST20151123/R-Interface/source_all.R")
output.file  <- paste0("..//Outputs//",river,"_",siteText,"_",min.date,"_",max.date)
output.file
site
taxon
min.date
max.date
by
output.file
F.run.passage     ( site, taxon,      min.date, max.date, by=by,        output.file=output.file,                     ci=TRUE            )
output.file  <- paste0("..//Outputs//",river,"_",siteText,"_",min.date,"_",max.date)
output.file
river        <- 'Mokelumne'
output.file  <- paste0("..//Outputs//",river,"_",siteText,"_",min.date,"_",max.date)
output.file
F.run.passage     ( site, taxon,      min.date, max.date, by=by,        output.file=output.file,                     ci=TRUE            )
river        <- 'Mokelumne'
site         <- 34000
siteText     <- 'testing'
run          <- 3
runText      <- 'Fall'
min.date     <- "2005-12-01"
max.date     <- "2006-07-30"
output.file  <- paste0("..//Outputs//",river,"_",siteText,"_",min.date,"_",max.date)
F.run.passage     ( site, taxon,      min.date, max.date, by=by,        output.file=output.file,                     ci=TRUE            )
#   ---- Check that times are less than 1 year apart
strt.dt <- as.POSIXct( min.date, format="%Y-%m-%d" )
end.dt <- as.POSIXct( max.date, format="%Y-%m-%d" )
run.season <- data.frame( start=strt.dt, end=end.dt )
dt.len <- difftime(end.dt, strt.dt, units="days")
if( dt.len > 366 )  stop("Cannot specify more than 365 days in F.passage. Check min.date and max.date.")
#   ---- Upon input, run is the runID (i.e., 3,4,etc.).  We changed the SQL to Connie's code,
#        and the catch data comes in as run.name (not code).  It is easiest to translate run
#        to the name here.  A bit inefficient, but not much.
ch <- odbcConnectAccess(db.file)
luRun <- sqlFetch(ch, "luRun")
run.name <<- luRun$run[ luRun$runID == run ]
close(ch)
#   ---- Start a progress bar
progbar <<- winProgressBar( "Production estimate", label="Reading catch data and assigning plus-counts" )
#   ---- Fetch the catch and visit data
tmp.df   <- F.get.catch.data( site, taxon, min.date, max.date  )
catch.df <- tmp.df$catch   # All positive catches, all FinalRun and lifeStages, inflated for plus counts.  Zero catches (visits without catch) are NOT here.
visit.df <- tmp.df$visit   # the unique trap visits.  This will be used in a merge to get 0's later
if( nrow(catch.df) == 0 ){
stop( paste( "No catch records between", min.date, "and", max.date, ". Check dates and taxon."))
}
cat("\n\n")
cat(paste(rep("+",150), collapse="")); cat("\n")
cat("\n\n")
#   ---- Fetch efficiency data
setWinProgressBar( progbar, getWinProgressBar(progbar)*.7 + .3 , label="Reading efficiency data" )
release.df <- F.get.release.data( site, taxon, min.date, max.date  )
if( nrow(release.df) == 0 ){
stop( paste( "No efficiency trials between", min.date, "and", max.date, ". Check dates."))
}
cat("\n\n")
cat(paste(rep("+",150), collapse="")); cat("\n")
cat("\n\n")
#   =================================================================
#   by here, we have all the catch, visit, and release data for all runs and lifestages
#          of the species between min and max dates.
#   =================================================================
#   ---- Summarize catch data by batchDate. Upon return, catch.df has one line per trapPosition-batchDate combo during time trap was operating. missing times pre and post season
catch.df1 <- F.summarize.fish.visit( catch.df, 'inflated' )   # jason - 4/14/2015 - we summarize over lifeStage, w/o regard to unassigned.  this is what has always been done.
catch.df2 <- F.summarize.fish.visit( catch.df, 'assigned')    # jason - 4/14/2015 - we summarize over unassigned.  this is new, and necessary to break out by MEASURED, instead of CAUGHT.
#                   - the only reason we do this again is to get a different n.tot.
# bring in counts and stats of measured fish
assd <- catch.df2[catch.df2$Unassd != 'Unassigned' ,c('trapVisitID','lifeStage','FinalRun','n.tot','mean.fl','sd.fl')]    # & catch.df2$FinalRun == run.name not sure why we need to restrict to run here
colnames(assd) <- c('trapVisitID','lifeStage','FinalRun','n.Orig','mean.fl.Orig','sd.fl.Orig')
catch.dfA <- merge(catch.df1,assd,by=c('trapVisitID','lifeStage','FinalRun'),all.x=TRUE)
# bring in counts of unassigned (unmeasured) fish
unassd <- catch.df2[catch.df2$Unassd == 'Unassigned' ,c('trapVisitID','lifeStage','FinalRun','n.tot')]
colnames(unassd) <- c('trapVisitID','lifeStage','FinalRun','n.Unassd')
catch.df <- merge(catch.dfA,unassd,by=c('trapVisitID','lifeStage','FinalRun'),all.x=TRUE)
runs.found <- unique(catch.df$FinalRun)
runs.found <- runs.found[ !is.na(runs.found) ]
cat("\nRuns found between", min.date, "and", max.date, ":\n")
print(runs.found)
lstages <- unique(catch.df$lifeStage)
lstages <- lstages[ !is.na(lstages) ]   #   Don't need this,  I am pretty sure lifeStage is never missing here.
cat("\nLife stages found between", min.date, "and", max.date, ":\n")
print(lstages)
cat("\n\n")
cat(paste(rep("+",150), collapse="")); cat("\n")
cat("\n\n")
#   ---- Print the number of non-fishing periods
cat( paste("\nNumber of non-fishing intervals at all traps:", sum(visit.df$TrapStatus == "Not fishing"), "\n\n"))
#   ---- Compute passage
output.fn <- output.file
setWinProgressBar( progbar, getWinProgressBar(progbar)*.7 + .3, label="Computing passage" )
cat(paste(rep("*",80), collapse=""))
tmp.mess <- paste("Processing run", run, "-", run.name)
cat(paste("\n", tmp.mess, "\n"))
cat(paste(rep("*",80), collapse=""))
cat("\n\n")
barinc <- 1 / (length(lstages) * 6)
assign( "progbar", progbar, pos=.GlobalEnv )
indRun <- (catch.df$FinalRun == run.name ) & !is.na(catch.df$FinalRun)   # Don't need is.na clause.  FinalRun is never missing here.
catch.df.ls <- catch.df[ indRun , c("trapVisitID", "FinalRun", "lifeStage", 'n.Orig','mean.fl.Orig','sd.fl.Orig',"n.tot", "mean.fl", "sd.fl","n.Unassd")]     # jason 4/14/2015 - n.Orig col added in. 5/20/15 - n.Unassd added
#         catch.df.ls <- catch.df[ indRun , c("trapVisitID", "FinalRun", "lifeStage", "includeCatchID", "n.tot", "mean.fl", "sd.fl")]
#   ---- Merge in the visits to get zeros
catch.df.ls <- merge( visit.df, catch.df.ls, by="trapVisitID", all.x=T )
setWinProgressBar( progbar, getWinProgressBar(progbar)+barinc )
#   ---- Update the constant variables.  Missing n.tot when trap was fishing should be 0.
catch.df.ls$FinalRun[ is.na(catch.df.ls$FinalRun) ] <- run
catch.df.ls$lifeStage <- "All"
catch.df.ls$n.tot[ is.na(catch.df.ls$n.tot) & (catch.df.ls$TrapStatus == "Fishing") ] <- 0
catch.df.ls$n.Orig[ is.na(catch.df.ls$n.Orig) & (catch.df.ls$TrapStatus == "Fishing") ] <- 0
catch.df.ls$n.Unassd[ is.na(catch.df.ls$n.Unassd) & (catch.df.ls$TrapStatus == "Fishing") ] <- 0
#   ---- Compute passage
out.fn.root <- paste0(output.file, "_", run.name )
pass <- F.est.passage( catch.df.ls, release.df, by, out.fn.root, ci )
out.fn.roots <- attr(pass, "out.fn.list")
cat("Final run estimate: ")
cat(formatC(sum(pass$passage,na.rm=T),big.mark=",", digits=20))
cat("\n\n")
cat("\n\n")
cat(paste(rep("+",150), collapse="")); cat("\n")
cat("\n\n")
#   ---- Save .RData for later plotting (grand.df is produced by F.est.passage, and saved in .GlobalEnv
RData.fname <- "<none>"
!is.na(output.fn)
#   Fix up the pass table to pretty the output
tmp.df <- pass
if(by == 'week'){
# jason add.
db <- get( "db.file", env=.GlobalEnv )                                  #   Open ODBC channel
ch <- odbcConnectAccess(db)
the.dates <- sqlFetch( ch, "Dates" )                                    #   get the table that has the julian week labels.
the.dates <- subset(the.dates, as.Date(uniqueDate) >= min.date & as.Date(uniqueDate) <= max.date,c(uniqueDate,julianWeek,julianWeekLabel))
close(ch)
# can't figure out how to join on posix dates.  so cheating.
tmp.df$date.alone <- as.Date(strptime(tmp.df$date,format="%F"))
the.dates$date.alone <- as.Date(strptime(the.dates$uniqueDate,format="%F"))    # jason: from strftime to strptime. why the change?
tmp.df <- merge(tmp.df,the.dates,by = c("date.alone"),all.x=TRUE)
tmp.df$week <- paste0(strftime(tmp.df$date,"%Y"),"-",tmp.df$julianWeek,": ",tmp.df$julianWeekLabel)    #paste0(myYear,'-',tmp.jday %/% 7 + 1)
tmp.df <- subset(tmp.df, select = -c(date.alone,uniqueDate,julianWeek,julianWeekLabel) )
}
tzn <- get("time.zone", .GlobalEnv )
tmp.df$date <- as.POSIXct( strptime( format(tmp.df$date, "%Y-%m-%d"), "%Y-%m-%d", tz=tzn),tz=tzn)
tmp.df$passage <- round(tmp.df$passage)
tmp.df$lower.95 <- round(tmp.df$lower.95)
tmp.df$upper.95 <- round(tmp.df$upper.95)
tmp.df$meanForkLenMM <- round(tmp.df$meanForkLenMM,1)
tmp.df$sdForkLenMM <- round(tmp.df$sdForkLenMM,2)
tmp.df$pct.imputed.catch <- round(tmp.df$pct.imputed.catch, 3)
tmp.df$sampleLengthHrs <- round(tmp.df$sampleLengthHrs,1)
tmp.df$sampleLengthDays <- round(tmp.df$sampleLengthDays,2)
names(tmp.df)[ names(tmp.df) == "pct.imputed.catch" ] <- "propImputedCatch"
names(tmp.df)[ names(tmp.df) == "lower.95" ] <- "lower95pctCI"
names(tmp.df)[ names(tmp.df) == "upper.95" ] <- "upper95pctCI"
names(tmp.df)[ names(tmp.df) == "nForkLenMM" ] <- "numFishMeasured"
if( by == "day" ){
#   Merge in the trapsOperating column
tO <- attr(pass, "trapsOperating")
tmp.df <- merge( tmp.df, tO, by.x="date", by.y="batchDate", all.x=T )
#   For aesthetics, change number fish measured on days in gaps from NA to 0
tmp.df$numFishMeasured[ is.na(tmp.df$numFishMeasured) & (tmp.df$nTrapsOperating == 0) ] <- 0
}
by
#   Open file and write out header.
out.pass.table <- paste(output.fn, "_passage_table.csv", sep="")
rs <- paste( format(run.season[1], "%d-%b-%Y"), "to", format(run.season[2], "%d-%b-%Y"))
nms <- names(tmp.df)[1]
for( i in 2:length(names(tmp.df))){
if(by == 'day'){
nms <- paste(nms, ",", names(tmp.df)[i], sep="")
} else {
if(i != 3){                                                # jason add:  put in this condition to make 'date' not print. doug doesnt like it.
nms <- paste(nms, ",", names(tmp.df)[i], sep="")
}
}
}
if(by == 'day'){
nms <- gsub('date,', '', nms)     # by == day results in a slightly different format for tmp.df than the other three.
}
cat(paste("Writing passage estimates to", out.pass.table, "\n"))
sink(out.pass.table)
cat(paste("Site=,", catch.df$siteName[1], "\n", sep=""))
cat(paste("Site ID=,", catch.df$siteID[1], "\n", sep=""))
cat(paste("Species ID=,", taxon, "\n", sep=""))
cat(paste("Run =,", run.name, "\n", sep=""))
cat(paste("Lifestage =,", catch.df.ls$lifeStage[1], "\n", sep=""))
cat(paste("Summarized by=,", by, "\n", sep=""))
cat(paste("Dates included=,", rs, "\n", sep=""))
cat("\n")
cat(nms)
cat("\n")
sink()
tmp.df$date <- NULL                                              # jason add:  make sure the whole column of date doesnt print.
#   Write out the table
write.table( tmp.df, file=out.pass.table, sep=",", append=TRUE, row.names=FALSE, col.names=FALSE)
#   Write out the total passage. No other totals in file.
#sink(out.pass.table, append=TRUE)
#cat(paste("Total:,", round(sum(pass$passage,na.rm=T)), "\n"))
#sink()
out.fn.roots <- c(out.fn.roots, out.pass.table)
FinalRun
runText
F.run.passage     ( site, taxon,      min.date, max.date, by=by,        output.file=output.file,                     ci=TRUE            )
#   ---- Check that times are less than 1 year apart
strt.dt <- as.POSIXct( min.date, format="%Y-%m-%d" )
end.dt <- as.POSIXct( max.date, format="%Y-%m-%d" )
run.season <- data.frame( start=strt.dt, end=end.dt )
dt.len <- difftime(end.dt, strt.dt, units="days")
if( dt.len > 366 )  stop("Cannot specify more than 365 days in F.passage. Check min.date and max.date.")
#   ---- Upon input, run is the runID (i.e., 3,4,etc.).  We changed the SQL to Connie's code,
#        and the catch data comes in as run.name (not code).  It is easiest to translate run
#        to the name here.  A bit inefficient, but not much.
ch <- odbcConnectAccess(db.file)
luRun <- sqlFetch(ch, "luRun")
run.name <<- luRun$run[ luRun$runID == run ]
close(ch)
#   ---- Start a progress bar
progbar <<- winProgressBar( "Production estimate", label="Reading catch data and assigning plus-counts" )
#   ---- Fetch the catch and visit data
tmp.df   <- F.get.catch.data( site, taxon, min.date, max.date  )
catch.df <- tmp.df$catch   # All positive catches, all FinalRun and lifeStages, inflated for plus counts.  Zero catches (visits without catch) are NOT here.
visit.df <- tmp.df$visit   # the unique trap visits.  This will be used in a merge to get 0's later
if( nrow(catch.df) == 0 ){
stop( paste( "No catch records between", min.date, "and", max.date, ". Check dates and taxon."))
}
cat("\n\n")
cat(paste(rep("+",150), collapse="")); cat("\n")
cat("\n\n")
#   ---- Fetch efficiency data
setWinProgressBar( progbar, getWinProgressBar(progbar)*.7 + .3 , label="Reading efficiency data" )
release.df <- F.get.release.data( site, taxon, min.date, max.date  )
if( nrow(release.df) == 0 ){
stop( paste( "No efficiency trials between", min.date, "and", max.date, ". Check dates."))
}
cat("\n\n")
cat(paste(rep("+",150), collapse="")); cat("\n")
cat("\n\n")
#   =================================================================
#   by here, we have all the catch, visit, and release data for all runs and lifestages
#          of the species between min and max dates.
#   =================================================================
catch.df1 <- F.summarize.fish.visit( catch.df, 'inflated' )   # jason - 4/14/2015 - we summarize over lifeStage, w/o regard to unassigned.  this is what has always been done.
head(catch.df)
dim(catch.df)
catch <- catch.df
variable <- 'inflated'
head(catch)
table(catch$forkLength,exclude=NULL)
table(catch$Unassd,exclude=NULL)
catch[catch$Unassd == 'Unassigned',]$forkLength <- NA
catch[catch$Unassd == 'Unassigned',]$forkLength
if(nrow(catch[catch$Unassd == 'Unassigned',]) > 0){
catch[catch$Unassd == 'Unassigned',]$forkLength <- NA
}
